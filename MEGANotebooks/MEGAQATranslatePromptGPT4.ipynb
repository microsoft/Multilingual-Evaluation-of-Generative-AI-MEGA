{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "8b0d19e8",
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "a19a5cff",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.chdir(\"../\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "026b1300",
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "import random\n",
                "import requests, uuid, json\n",
                "from typing import List\n",
                "import spacy\n",
                "import openai\n",
                "import numpy as np\n",
                "import wandb\n",
                "from datasets import load_dataset\n",
                "from mega.data.load_datasets import load_xnli_dataset\n",
                "from mega.data.data_utils import choose_few_shot_examples\n",
                "from mega.prompting.instructions import INSTRUCTIONS\n",
                "from mega.prompting.prompting_utils import load_prompt_template\n",
                "from mega.utils.env_utils import load_openai_env_variables\n",
                "from mega.models.completion_models import get_model_pred, gpt3x_completion\n",
                "from mega.prompting.prompting_utils import construct_prompt, construct_qa_prompt\n",
                "from tqdm import tqdm\n",
                "from evaluate import load\n",
                "\n",
                "# Translator setup for bing\n",
                "endpoint = \"https://api.cognitive.microsofttranslator.com/\"\n",
                "with open(\"keys/bing_translate_key.txt\") as f:\n",
                "    subscription_key = f.read().split(\"\\n\")[0]\n",
                "    \n",
                "# Add your location, also known as region. The default is global.\n",
                "# This is required if using a Cognitive Services resource.\n",
                "location = \"centralindia\"\n",
                "path = \"/translate?api-version=3.0\"\n",
                "constructed_url = endpoint + path\n",
                "\n",
                "headers = {\n",
                "    \"Ocp-Apim-Subscription-Key\": subscription_key,\n",
                "    \"Content-type\": \"application/json\",\n",
                "    \"X-ClientTraceId\": str(uuid.uuid4()),\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "35e9f7fe",
            "metadata": {},
            "outputs": [],
            "source": [
                "random.seed(42)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "73ef56fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make sure that {env_name}.env file is present in the envs/ directory\n",
                "env_name = \"gpt4v2\"\n",
                "load_env(env_name=env_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "82cce2c0",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'2023-03-15-preview'"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "openai.api_version"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "1992175f",
            "metadata": {},
            "outputs": [],
            "source": [
                "model = \"gpt-4-32k\"\n",
                "pivot_lang = \"es\"\n",
                "tgt_lang = \"es\"\n",
                "prompt_name = \"answer_given_context_and_question\"\n",
                "few_shot_k = 4\n",
                "dataset = \"xquad\"\n",
                "short_contexts = False\n",
                "max_tokens = 100"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "0fc5117e",
            "metadata": {
                "scrolled": false
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
                        "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkabirahuja2431\u001b[0m (\u001b[33mscai-msri\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.15.0"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/home/t-kabirahuja/work/repos/MultilingualBlanketEval/wandb/run-20230425_083651-0o98ah1x</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Syncing run <strong><a href='https://wandb.ai/scai-msri/GPT-4-eval/runs/0o98ah1x' target=\"_blank\">super-plasma-79</a></strong> to <a href='https://wandb.ai/scai-msri/GPT-4-eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/scai-msri/GPT-4-eval' target=\"_blank\">https://wandb.ai/scai-msri/GPT-4-eval</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/scai-msri/GPT-4-eval/runs/0o98ah1x' target=\"_blank\">https://wandb.ai/scai-msri/GPT-4-eval/runs/0o98ah1x</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/scai-msri/GPT-4-eval/runs/0o98ah1x?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
                        ],
                        "text/plain": [
                            "<wandb.sdk.wandb_run.Run at 0x7f5593fecf40>"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "config = {\n",
                "    \"model\" : model,\n",
                "    \"pivot_lang\": pivot_lang,\n",
                "    \"tgt_lang\": tgt_lang,\n",
                "    \"prompt_name\": prompt_name,\n",
                "    \"few_shot_k\": few_shot_k,\n",
                "    \"dataset\": dataset,\n",
                "    \"short_contexts\": short_contexts,\n",
                "    \"max_tokens\": max_tokens\n",
                "}\n",
                "\n",
                "wandb.init(project=\"GPT-4-eval\", entity=\"scai-msri\", config=config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "645bc52f",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpacySentenceTokenizer:\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.nlp = spacy.load('xx_ent_wiki_sm')\n",
                "        self.nlp.add_pipe(\"sentencizer\")\n",
                "        \n",
                "    def __call__(self, text: str) -> List[str]:\n",
                "        return list(map(lambda span: span.text, self.nlp(text).sents))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "57a7a04d",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_qa_dataset(dataset_name, lang, split, dataset_frac = 1, translate_test = False):\n",
                "    if dataset_name == \"indicqa\":\n",
                "        if split != \"train\":\n",
                "            dataset = load_dataset(\"ai4bharat/IndicQA\", f\"indicqa.{lang}\")[split]\n",
                "        else:\n",
                "            dataset = load_dataset(\"squad\")[split]\n",
                "    elif dataset_name == \"xquad\":\n",
                "        if split != \"train\":\n",
                "            dataset = load_dataset(\"xquad\", f\"xquad.{lang}\")[split]\n",
                "        else:\n",
                "            dataset = load_dataset(\"squad\")[split]\n",
                "    elif dataset_name == \"tydiqa\":\n",
                "        dataset = load_dataset(\"tydiqa\", 'secondary_task')[split]\n",
                "        dataset = dataset.map(lambda example: {\"lang\" : TYDIQA_LANG2CODES[example[\"id\"].split(\"-\")[0]]})\n",
                "        dataset = dataset.filter(lambda example: example[\"lang\"] == lang)\n",
                "    elif dataset_name == \"mlqa\":\n",
                "        if split == \"train\":\n",
                "            print(\"No Training Data for MLQA, switching to validation!\")\n",
                "            split = \"validation\"\n",
                "        if translate_test:\n",
                "            dataset_name = f\"mlqa-translate-test.{lang}\"\n",
                "        else:\n",
                "            dataset_name = f\"mlqa.{lang}.{lang}\"\n",
                "        \n",
                "        dataset = load_dataset(\"mlqa\", dataset_name)[split]\n",
                "    \n",
                "    else:\n",
                "        raise NotImplementedError()\n",
                "    N = len(dataset)\n",
                "    selector = np.arange(int(N * dataset_frac))\n",
                "    return dataset.select(selector)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "edc89fd7",
            "metadata": {},
            "outputs": [],
            "source": [
                "TYDIQA_LANG2CODES = {\n",
                "    \"bengali\": \"bn\",\n",
                "    \"korean\" : \"ko\",\n",
                "    \"swahili\" : \"sw\",\n",
                "    \"english\" : \"en\",\n",
                "    \"indonesian\" :\"id\",\n",
                "    \"arabic\" : \"ar\",\n",
                "    \"finnish\" : \"fi\",\n",
                "    \"telugu\" : \"te\",\n",
                "    \"russian\" : \"ru\"\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "a527f74b",
            "metadata": {},
            "outputs": [],
            "source": [
                "LangCodes2LangNames = {\n",
                "    \"en\" : \"English\",\n",
                "    \"ko\" : \"Korean\",\n",
                "    \"es\" : \"Spanish\",\n",
                "    \"de\" : \"German\",\n",
                "    \"fr\" : \"French\",\n",
                "    \"zh\" : \"Chinese\"\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "6a81d928",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Found cached dataset xquad (/home/t-kabirahuja/.cache/huggingface/datasets/xquad/xquad.es/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3e32cf7f8b124484a539c4f921560d87",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/1 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Found cached dataset xquad (/home/t-kabirahuja/.cache/huggingface/datasets/xquad/xquad.es/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4d62410e869b42e18311ab22829d8ee0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/1 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "train_dataset = load_qa_dataset(dataset,\n",
                "                                lang = pivot_lang,\n",
                "                                split=\"validation\")\n",
                "test_dataset = load_qa_dataset(dataset,\n",
                "                                lang = tgt_lang,\n",
                "                                split=\"validation\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "5782b80f",
            "metadata": {},
            "outputs": [],
            "source": [
                "if short_contexts:\n",
                "    sent_tokenizer = SpacySentenceTokenizer() \n",
                "\n",
                "    train_dataset = train_dataset.map(lambda example: {\n",
                "        \"context\": [sent for sent in sent_tokenizer(example[\"context\"]) if example[\"answers\"][\"text\"][0] in sent][0]\n",
                "    }, num_proc = 8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "98827b9b",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_examples = choose_few_shot_examples(\n",
                "        train_dataset, few_shot_k, selection_criteria=\"random\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "9a4cb23b",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_ex_ids = [train_example[\"id\"] for train_example in train_examples]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "27aea4f4",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['5725cc38ec44d21400f3d5bb',\n",
                            " '57097d63ed30961900e841fe',\n",
                            " '570d3468b3d812140066d543',\n",
                            " '56e7586d37bdd419002c3eb5']"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_ex_ids"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "a136e3c7",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Dataset({\n",
                            "    features: ['id', 'context', 'question', 'answers'],\n",
                            "    num_rows: 1190\n",
                            "})"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "test_dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "14809205",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading cached processed dataset at /home/t-kabirahuja/.cache/huggingface/datasets/xquad/xquad.es/1.0.0/39e1ff0497cbbfb79bbff61024031c10872bbd7c4fd8bc250207a965c39d3336/cache-fb43d141df00a9d9.arrow\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "Dataset({\n",
                            "    features: ['id', 'context', 'question', 'answers'],\n",
                            "    num_rows: 1186\n",
                            "})"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "test_dataset = test_dataset.filter(lambda example: example[\"id\"] not in train_ex_ids)\n",
                "test_dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "b287a181",
            "metadata": {},
            "outputs": [],
            "source": [
                "PROMPTS_DICT = {\n",
                "    \"answer_given_context_and_question\" : \"\"\"{context}\n",
                "    Q: {question}\n",
                "\n",
                "    Referring to the passage above, the correct answer to the given question is:\n",
                "    {answer}\"\"\",\n",
                "    \n",
                "    \"lang_instruct_answer_given_context_and_question\" : \"\"\"{context}\n",
                "    Q: {question}\n",
                "\n",
                "    Referring to the passage above, the correct answer to the given question is? Please try to answer in {language} and ensure that the answer appears as it is in the passage.\n",
                "    A: {answer}\"\"\",\n",
                "    \n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "a45e8d1f",
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt_template = PROMPTS_DICT[prompt_name]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "1eb47ad6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "You are an NLP assistant whose purpose is to solve reading comprehension problems. You will be provided questions on a set of passages and you will need to provide the answer as it appears in the passage. The answer should be in the same language as the question and the passage.\n"
                    ]
                }
            ],
            "source": [
                "# Loading instruction for the task\n",
                "instruction = INSTRUCTIONS[dataset]\n",
                "print(instruction)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "71060cf0",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'role': 'system',\n",
                            " 'content': 'You are an NLP assistant whose purpose is to solve reading comprehension problems. You will be provided questions on a set of passages and you will need to provide the answer as it appears in the passage. The answer should be in the same language as the question and the passage.'}"
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "instruction_prompt = {\"role\": \"system\", \"content\": instruction}\n",
                "instruction_prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "b30de756",
            "metadata": {},
            "outputs": [],
            "source": [
                "def translate_with_bing(text: str, src: str, dest: str) -> str:\n",
                "    \"\"\"Uses the bing translator to translate `text` from `src` language to `dest` language\n",
                "\n",
                "    Args:\n",
                "        text (str): Text to translate\n",
                "        src (str): Source language to translate from\n",
                "        dest (str): Language to translate to\n",
                "\n",
                "    Returns:\n",
                "        str: Translated text\n",
                "    \"\"\"\n",
                "    params = {\"api-version\": \"3.0\", \"from\": src, \"to\": [dest]}\n",
                "    body = [{\"text\": text}]\n",
                "\n",
                "    try:\n",
                "        request = requests.post(\n",
                "            constructed_url, params=params, headers=headers, json=body\n",
                "        )\n",
                "        response = request.json()\n",
                "        # pdb.set_trace()\n",
                "        translation = response[0][\"translations\"][0][\"text\"]\n",
                "    except:\n",
                "        pdb.set_trace()\n",
                "        translation = \"<MT Failed>\"\n",
                "\n",
                "    return translation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "0a85e8d4",
            "metadata": {},
            "outputs": [],
            "source": [
                "def fill_template(template, example, fill_answer=True):\n",
                "    if fill_answer:\n",
                "        return template.replace(\"{context}\", example[\"context\"])\\\n",
                "                .replace(\"{question}\", example[\"question\"])\\\n",
                "                .replace(\"{answer}\", example[\"answers\"][\"text\"][0])\n",
                "    else:\n",
                "        return template.replace(\"{context}\", example[\"context\"])\\\n",
                "                .replace(\"{question}\", example[\"question\"])\\\n",
                "                .replace(\"{answer}\", \"\").strip()\n",
                "    \n",
                "def construct_translate_cot_prompt(example, lang, test=False):\n",
                "        \n",
                "    answer_step_by_step_format = \"Let's do it step by step.\"\n",
                "    answer_passage_trans_format = \"Translation of the passage in English is: \\\"{translated_en_passage}\\\"\"\n",
                "    answer_question_trans_format = \"Translation of the question in English is: \\\"{translated_en_question}\\\"\"\n",
                "    answer_en_answer_format = \"Then the answer in English will be: {answer_en}\"\n",
                "    answer_format = \"Hence the final answer in {lang} is: {answer}\"\n",
                "    \n",
                "    \n",
                "    user_prompt = {\"role\": \"user\", \"content\": fill_template(prompt_template, example, fill_answer=False)}\n",
                "    if test:\n",
                "        return [user_prompt]\n",
                "    \n",
                "    assistant_answers = [\n",
                "        answer_step_by_step_format,\n",
                "        answer_passage_trans_format.replace(\"{translated_en_passage}\", translate_with_bing(example[\"context\"], src = lang, dest = \"en\")),\n",
                "        answer_question_trans_format.replace(\"{translated_en_question}\", translate_with_bing(example[\"question\"], src = lang, dest = \"en\")),\n",
                "        answer_en_answer_format.replace(\"{answer_en}\", translate_with_bing(example[\"answers\"][\"text\"][0], src = lang, dest = \"en\")),\n",
                "        answer_format.replace(\"{answer}\", example[\"answers\"][\"text\"][0]).replace(\"{lang}\", LangCodes2LangNames[lang])\n",
                "    ]\n",
                "\n",
                "    assistant_answers = [{\"role\": \"assistant\", \"content\": answer} for answer in assistant_answers]\n",
                "    return [user_prompt] +  assistant_answers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "cd1579ec",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'text': ['308'], 'answer_start': [133]}"
                        ]
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_dataset[0][\"answers\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "274025ad",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'id': '56beb4343aeaaa14008c925b',\n",
                            " 'context': '\\ufeffLos Panthers, que además de liderar las intercepciones de la NFL con 24 y contar con cuatro jugadores de la Pro Bowl, cedieron solo 308 puntos en defensa y se sitúan en el sexto lugar de la liga. Kawann Short, tacle defensivo de la Pro Bowl, lideró al equipo con 11 capturas, 3 balones sueltos forzados y 2 recuperaciones. A su vez, el liniero Mario Addison, consiguió 6 capturas y media. En la línea de los Panthers, también destacó como ala defensiva el veterano Jared Allen ―5 veces jugador de la Pro Bowl y que fue el líder, en activo, de capturas de la NFL con 136― junto con el también ala defensiva Kony Ealy, que lleva 5 capturas en solo 9 partidos como titular. Detrás de ellos, Thomas Davis y Luke Kuechly, dos de los tres apoyadores titulares que también han sido seleccionados para jugar la Pro Bowl. Davis se hizo con 5 capturas y media, 4 balones sueltos forzados y 4 intercepciones, mientras que Kuechly lideró al equipo en derribos (118), forzó 2 balones sueltos e interceptó 4 pases. La secundaria de Carolina contó, por un lado, con la seguridad del jugador de la Pro Bowl Kurt Coleman que asumió las riendas del equipo gracias a sus 7 intercepciones (nunca había conseguido tantas hasta ahora) y a sus 88 derribos, y, por otro lado, con el esquinero Josh Norman, también jugador de la Pro Bowl y que a pesar de haber estado de capa caída durante la temporada, consiguió 4 intercepciones, de las cuales dos se convirtieron en touchdowns.',\n",
                            " 'question': '¿Cuántos puntos dejaron escapar en defensa los Panthers?',\n",
                            " 'answers': {'text': ['308'], 'answer_start': [133]}}"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_dataset[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "608298be",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[{'role': 'user',\n",
                            "  'content': '\\ufeffLos Panthers, que además de liderar las intercepciones de la NFL con 24 y contar con cuatro jugadores de la Pro Bowl, cedieron solo 308 puntos en defensa y se sitúan en el sexto lugar de la liga. Kawann Short, tacle defensivo de la Pro Bowl, lideró al equipo con 11 capturas, 3 balones sueltos forzados y 2 recuperaciones. A su vez, el liniero Mario Addison, consiguió 6 capturas y media. En la línea de los Panthers, también destacó como ala defensiva el veterano Jared Allen ―5 veces jugador de la Pro Bowl y que fue el líder, en activo, de capturas de la NFL con 136― junto con el también ala defensiva Kony Ealy, que lleva 5 capturas en solo 9 partidos como titular. Detrás de ellos, Thomas Davis y Luke Kuechly, dos de los tres apoyadores titulares que también han sido seleccionados para jugar la Pro Bowl. Davis se hizo con 5 capturas y media, 4 balones sueltos forzados y 4 intercepciones, mientras que Kuechly lideró al equipo en derribos (118), forzó 2 balones sueltos e interceptó 4 pases. La secundaria de Carolina contó, por un lado, con la seguridad del jugador de la Pro Bowl Kurt Coleman que asumió las riendas del equipo gracias a sus 7 intercepciones (nunca había conseguido tantas hasta ahora) y a sus 88 derribos, y, por otro lado, con el esquinero Josh Norman, también jugador de la Pro Bowl y que a pesar de haber estado de capa caída durante la temporada, consiguió 4 intercepciones, de las cuales dos se convirtieron en touchdowns.\\n    Q: ¿Cuántas capturas ha conseguido Jared Allen en su carrera?\\n\\n    Referring to the passage above, the correct answer to the given question is:'},\n",
                            " {'role': 'assistant', 'content': \"Let's do it step by step.\"},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Translation of the passage in English is: \"The Panthers, who in addition to leading NFL interceptions with 24 and four Pro Bowl players, gave up only 308 points on defense and are in sixth place in the league. Pro Bowl defensive tackle Kawann Short led the team with 11 sacks, 3 forced fumbles and 2 recoveries. In turn, lineman Mario Addison, got 6 and a half catches. In the line of the Panthers, also stood out as a defensive end the veteran Jared Allen ―5 times Pro Bowl player and who was the leader, active, of captures of the NFL with 136― along with the also defensive wing Kony Ealy, who has 5 captures in only 9 games as a starter. Behind them, Thomas Davis and Luke Kuechly, two of the three starting linebackers who have also been selected to play in the Pro Bowl. Davis had 5 1/2 sacks, 4 forced fumbles and 4 interceptions, while Kuechly led the team in takedowns (118), forced 2 fumbles and intercepted 4 passes. The Carolina secondary had, on the one hand, the security of the Pro Bowl player Kurt Coleman who assumed the reins of the team thanks to his 7 interceptions (he had never achieved so many so far) and his 88 takedowns, and, on the other hand, with cornerback Josh Norman, also a Pro Bowl player and who despite having been in a state of collapse during the season,  He had 4 interceptions, of which two were touchdowns.\"'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Translation of the question in English is: \"How many sacks has Jared Allen made in his career?\"'},\n",
                            " {'role': 'assistant', 'content': 'Then the answer in English will be: 136'},\n",
                            " {'role': 'assistant', 'content': 'Hence the final answer in Spanish is: 136'}]"
                        ]
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "construct_translate_cot_prompt(\n",
                "    train_dataset[1],\n",
                "    lang = tgt_lang\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "466959d6",
            "metadata": {},
            "outputs": [],
            "source": [
                "few_shot_prompts = []\n",
                "for example in train_examples:\n",
                "    few_shot_prompts += construct_translate_cot_prompt(example, lang = tgt_lang)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "a805ade5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'role': 'assistant', 'content': 'Then the answer in English will be: with common rules for coal and steel'}\n"
                    ]
                }
            ],
            "source": [
                "print(few_shot_prompts[4])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "id": "b8367f96",
            "metadata": {},
            "outputs": [],
            "source": [
                "squad_metric = load(\"squad\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "7fd344b8",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[{'role': 'system',\n",
                            "  'content': 'You are an NLP assistant whose purpose is to solve reading comprehension problems. You will be provided questions on a set of passages and you will need to provide the answer as it appears in the passage. The answer should be in the same language as the question and the passage.'},\n",
                            " {'role': 'user',\n",
                            "  'content': 'Los principales Tratados que forman la Unión Europea comenzaron con reglas comunes para el carbón y el acero, y luego la energía atómica, pero se establecieron instituciones más integrales y formales mediante el Tratado de Roma de 1957 y el Tratado de Maastricht de 1992 (ahora: TFEU). Durante los años sesenta y setenta se introdujeron pequeñas modificaciones. Se firmaron importantes tratados de enmienda para completar el desarrollo de un mercado interior único en el Acta Única Europea 1986, para promover el desarrollo de una Europa más social en el Tratado de Ámsterdam de 1997 y para introducir pequeñas modificaciones en el poder relativo de los Estados miembros en las instituciones de la UE en el Tratado de Niza de 2001 y en el Tratado de Lisboa de 2007. Desde su creación, se han adherido más Estados miembros a través de una serie de tratados de adhesión, desde el Reino Unido, Irlanda, Dinamarca y Noruega en 1972 (aunque Noruega terminó por no adherirse), Grecia en 1979, España y Portugal en 1985, Austria, Finlandia, Noruega y Suecia en 1994 (aunque de nuevo Noruega no se adhirió a la Unión Europea debido a la falta de apoyo en el referéndum), la República Checa, Chipre, Estonia, Hungría, Letonia, Lituania, Malta, Polonia, Eslovaquia y Eslovenia en 2004, Rumania y Bulgaria en 2007 y Croacia en 2013. Groenlandia firmó un Tratado en 1985 que le otorga un estatus especial.\\n    Q: ¿Cómo surgieron los principales tratados que conforman la Unión Europea?\\n\\n    Referring to the passage above, the correct answer to the given question is:'},\n",
                            " {'role': 'assistant', 'content': \"Let's do it step by step.\"},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Translation of the passage in English is: \"The main treaties that make up the European Union began with common rules for coal and steel, and then atomic energy, but more comprehensive and formal institutions were established by the 1957 Treaty of Rome and the 1992 Maastricht Treaty (now: TFEU). During the sixties and seventies small modifications were introduced. Important amendment treaties were signed to complete the development of a single internal market in the 1986 Single European Act, to promote the development of a more social Europe in the 1997 Treaty of Amsterdam and to introduce minor changes to the relative power of the Member States in the EU institutions in the 2001 Treaty of Nice and the 2007 Treaty of Lisbon. Since its creation, more Member States have acceded through a series of accession treaties, from the United Kingdom, Ireland, Denmark and Norway in 1972 (although Norway eventually did not join), Greece in 1979, Spain and Portugal in 1985, Austria, Finland, Norway and Sweden in 1994 (although Norway again did not join the European Union due to lack of support in the referendum),  the Czech Republic, Cyprus, Estonia, Hungary, Latvia, Lithuania, Malta, Poland, Slovakia and Slovenia in 2004, Romania and Bulgaria in 2007 and Croatia in 2013. Greenland signed a treaty in 1985 that gives it special status.\"'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Translation of the question in English is: \"How did the main treaties that make up the European Union come about?\"'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Then the answer in English will be: with common rules for coal and steel'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Hence the final answer in Spanish is: con reglas comunes para el carbón y el acero'},\n",
                            " {'role': 'user',\n",
                            "  'content': 'Los acuerdos incluyen tarifas anuales fijas de transporte de 30 millones de libras para los canales si los dos proveedores de canales son capaces de garantizar pagos limitados adicionales si sus canales alcanzan determinados objetivos de rendimiento. Actualmente no hay ninguna indicación en cuanto a si el nuevo acuerdo incluye el vídeo bajo demanda adicional y el contenido de alta definición que anteriormente había ofrecido BSkyB. Como parte de los acuerdos, tanto BSkyB como Virgin Media decidieron poner fin a todas las actuaciones judiciales ante el tribunal superior relacionadas con el transporte de sus respectivos canales básicos.\\n    Q: ¿Qué empresa acordó poner fin a las actuaciones judiciales contra BSkyB ante el tribunal superior?\\n\\n    Referring to the passage above, the correct answer to the given question is:'},\n",
                            " {'role': 'assistant', 'content': \"Let's do it step by step.\"},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Translation of the passage in English is: \"The agreements include fixed annual transport fees of £30 million for channels if the two channel providers are able to guarantee additional limited payments if their channels meet certain performance targets. There is currently no indication as to whether the new deal includes the additional video-on-demand and high-definition content previously offered by BSkyB. As part of the settlements, both BSkyB and Virgin Media decided to end all court proceedings before the high court relating to the transport of their respective basic channels.\"'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Translation of the question in English is: \"Which company agreed to end the legal proceedings against BSkyB before the high court?\"'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Then the answer in English will be: Virgin Media'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Hence the final answer in Spanish is: Virgin Media'},\n",
                            " {'role': 'user',\n",
                            "  'content': 'Históricamente, Victoria ha sido la base de las plantas de fabricación de las principales marcas de coches, Ford, Toyota y Holden; sin embargo, los anuncios de cierre de estas tres empresas en el siglo XXI significarán que Australia ya no será una base de la industria automovilística mundial tras la declaración de Toyota de febrero de 2014 en la que se apuntaba a 2017 como año de cierre. El anuncio de Holden se produjo en mayo de 2013, seguido por la decisión de Ford de diciembre de ese mismo año (las plantas que tiene Ford en Victoria, situadas en Broadmeadows y Geelong, cerrarán el de octubre de 2016).\\n    Q: ¿Qué tipo de planta de fabricación va a cerrar dentro de poco en Victoria?\\n\\n    Referring to the passage above, the correct answer to the given question is:'},\n",
                            " {'role': 'assistant', 'content': \"Let's do it step by step.\"},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Translation of the passage in English is: \"Historically, Victoria has been the base of the manufacturing plants of the major car brands, Ford, Toyota and Holden; however, the announcements of closure of these three companies in the twenty-first century will mean that Australia will no longer be a base of the global car industry following Toyota\\'s declaration of February 2014 in which 2017 was pointed to as the closing year. Holden\\'s announcement came in May 2013, followed by Ford\\'s decision in December 2013 (Ford\\'s Victoria plants in Broadmeadows and Geelong will close in October 2016).\"'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Translation of the question in English is: \"What kind of manufacturing plant is going to close soon in Victoria?\"'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Then the answer in English will be: Main car brands'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Hence the final answer in Spanish is: principales marcas de coches'},\n",
                            " {'role': 'user',\n",
                            "  'content': '\\ufeffEn el pasado, el castigo físico (azotes en las nalgas, golpes, castigo físico o golpear con una vara al estudiante para causarle dolor físico) era una de las formas más comunes de disciplina escolar en gran parte del mundo. La mayoría de los países occidentales y algunos otros lo han prohibido, pero sigue siendo legal en Estados Unidos según una decisión del Tribunal Supremo de Estados Unidos de 1977 que consideró que pegar no violaba la Constitución estadounidense.\\n    Q: ¿En qué país occidental sigue permitiéndose el castigo físico?\\n\\n    Referring to the passage above, the correct answer to the given question is:'},\n",
                            " {'role': 'assistant', 'content': \"Let's do it step by step.\"},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Translation of the passage in English is: \"In the past, physical punishment (whipping the buttocks, beatings, physical punishment, or beating the student with a cane to cause physical pain) was one of the most common forms of school discipline in much of the world. Most Western countries and a few others have banned it, but it remains legal in the United States according to a 1977 U.S. Supreme Court decision that found that hitting did not violate the U.S. Constitution.\"'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Translation of the question in English is: \"In which Western country is corporal punishment still permitted?\"'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Then the answer in English will be: United States'},\n",
                            " {'role': 'assistant',\n",
                            "  'content': 'Hence the final answer in Spanish is: Estados Unidos'},\n",
                            " {'role': 'user',\n",
                            "  'content': 'Sin embargo, debido a las diferentes declaraciones que realizaba, sus opiniones religiosas siguen siendo confusas. Por ejemplo, en su artículo \" Una máquina para acabar con la guerra\", publicado en 1937, Tesla declaraba lo siguiente:\\n    Q: ¿Qué artículo fue publicado en 1937?\\n\\n    Referring to the passage above, the correct answer to the given question is:'}]"
                        ]
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "test_example = test_dataset[132]\n",
                "\n",
                "\n",
                "test_prompt = construct_translate_cot_prompt(test_example, tgt_lang, test=True)\n",
                "\n",
                "prompt = [instruction_prompt] + few_shot_prompts + test_prompt\n",
                "label = test_example[\"answers\"][\"text\"][0]\n",
                "\n",
                "\n",
                "prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "70b85ef5",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "list"
                        ]
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "type(prompt)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "id": "02ecd577",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Exceeded Rate Limit. Waiting for 2 seconds\n",
                        "Exceeded Rate Limit. Waiting for 4 seconds\n",
                        "Exceeded Rate Limit. Waiting for 8 seconds\n",
                        "Exceeded Rate Limit. Waiting for 16 seconds\n",
                        "Exceeded Rate Limit. Waiting for 32 seconds\n",
                        "Exceeded Rate Limit. Waiting for 64 seconds\n",
                        "Exceeded Rate Limit. Waiting for 2 seconds\n",
                        "Exceeded Rate Limit. Waiting for 4 seconds\n",
                        "Exceeded Rate Limit. Waiting for 8 seconds\n",
                        "Exceeded Rate Limit. Waiting for 2 seconds\n",
                        "Exceeded Rate Limit. Waiting for 4 seconds\n",
                        "Exceeded Rate Limit. Waiting for 8 seconds\n",
                        "Exceeded Rate Limit. Waiting for 16 seconds\n",
                        "Exceeded Rate Limit. Waiting for 32 seconds\n",
                        "Exceeded Rate Limit. Waiting for 64 seconds\n",
                        "Exceeded Rate Limit. Waiting for 128 seconds\n",
                        "Exceeded Rate Limit. Waiting for 2 seconds\n",
                        "Exceeded Rate Limit. Waiting for 4 seconds\n",
                        "Exceeded Rate Limit. Waiting for 8 seconds\n",
                        "Exceeded Rate Limit. Waiting for 16 seconds\n",
                        "Exceeded Rate Limit. Waiting for 32 seconds\n",
                        "Exceeded Rate Limit. Waiting for 64 seconds\n",
                        "Exceeded Rate Limit. Waiting for 128 seconds\n",
                        "Exceeded Rate Limit. Waiting for 256 seconds\n",
                        "Exceeded Rate Limit. Waiting for 512 seconds\n",
                        "Exceeded Rate Limit. Waiting for 1024 seconds\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
                        "File \u001b[0;32m~/work/repos/MultilingualBlanketEval/mega/models/completion_models.py:81\u001b[0m, in \u001b[0;36mgpt3x_completion\u001b[0;34m(prompt, model, run_details, num_evals_per_sec, backoff_base, backoff_rate, backoff_ceil, **model_params)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m run_details:\n",
                        "File \u001b[0;32m~/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n",
                        "File \u001b[0;32m~/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    138\u001b[0m (\n\u001b[1;32m    139\u001b[0m     deployment_id,\n\u001b[1;32m    140\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m )\n\u001b[0;32m--> 153\u001b[0m response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n",
                        "File \u001b[0;32m~/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m     method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m     request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m )\n\u001b[0;32m--> 226\u001b[0m resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
                        "File \u001b[0;32m~/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    626\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
                        "File \u001b[0;32m~/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
                        "\u001b[0;31mRateLimitError\u001b[0m: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mgpt3x_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: pred}]\n\u001b[1;32m     11\u001b[0m     preds\u001b[38;5;241m.\u001b[39mappend(pred)\n",
                        "File \u001b[0;32m~/work/repos/MultilingualBlanketEval/mega/models/completion_models.py:104\u001b[0m, in \u001b[0;36mgpt3x_completion\u001b[0;34m(prompt, model, run_details, num_evals_per_sec, backoff_base, backoff_rate, backoff_ceil, **model_params)\u001b[0m\n\u001b[1;32m    102\u001b[0m     sleep_time \u001b[38;5;241m=\u001b[39m backoff_base \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m backoff_count\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExceeded Rate Limit. Waiting for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 104\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (openai\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mAPIError,\u001b[38;5;167;01mTypeError\u001b[39;00m):\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "preds = []\n",
                "for _ in range(20):\n",
                "    \n",
                "    pred = gpt3x_completion(\n",
                "        prompt,\n",
                "        model,\n",
                "        temperature=0,\n",
                "        max_tokens = 100\n",
                "    )\n",
                "    prompt += [{\"role\": \"assistant\", \"content\": pred}]\n",
                "    preds.append(pred)\n",
                "    if \"Hence the final answer\" in pred:\n",
                "        break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "id": "9de36f6c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['', '', '']"
                        ]
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Bad pipe message: %s [b'\\xdf\\x08\\xc0\\xacFx\\xbcl\\x89?\\x9c\\xea\\xcdo\\xd7\\x9dN\\xb6 4\\x89i\\rbe\\x0f\\xca\\xea\\xd6\\xdc\\t\\xb1`9\\xe0\\xe5h\\xef\\x83\\x82\\xb0\\xcc\\xc6\\t\\xab\\x93\\xdc\\xf35\\xe3*\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t12', b'0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08']\n",
                        "Bad pipe message: %s [b'\\x08\\x08\\t\\x08\\n\\x08']\n",
                        "Bad pipe message: %s [b'\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\n",
                        "Bad pipe message: %s [b'']\n",
                        "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 \\xcb\\x03\\xd3p\\xec\\x90\\x9a\\x95\\xfaxL\\xa9i\\x85\\x81\\xef,.\\xc8#\\xaa\\x84']\n",
                        "Bad pipe message: %s [b\"A\\xca\\x1a;\\xed\\x1eE\\x8fY\\x0e=\\x7f\\x86\\xb1X\\xca\\xba\\xc3\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\", b'\\x03\\x03\\x02\\x03\\x03', b'']\n",
                        "Bad pipe message: %s [b'', b'\\x02']\n",
                        "Bad pipe message: %s [b'\\xb7U;`\\xf9\\xf9\\x00!\\n\\x87\\xf8\\x7f\\x8c\\xdfWN\\x84\\x88\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0']\n",
                        "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
                        "Bad pipe message: %s [b\"\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\"]\n",
                        "Bad pipe message: %s [b'\\xcer3\\x81H\\rN\\x9aJ\\xfc\\xbb\\x89L%\"t1\\xfe\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00']\n",
                        "Bad pipe message: %s [b'\\x06\\x00\\x17\\x00\\x03\\xc0\\x10']\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n",
                        "Exception in thread SockSrvRdThr:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
                        "    self.run()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 100, in run\n",
                        "    sreq = self._sock_client.read_server_request()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 274, in read_server_request\n",
                        "    data = self._read_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 248, in _read_packet_bytes\n",
                        "    rec = self._extract_packet_bytes()\n",
                        "  File \"/home/t-kabirahuja/work/repos/MultilingualBlanketEval/envs/megaenv/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 230, in _extract_packet_bytes\n",
                        "    assert magic == ord(\"W\")\n",
                        "AssertionError\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Bad pipe message: %s [b'VL\\xfa\\xa9\\xbb=\\xd5\\x80\\xd0']\n",
                        "Bad pipe message: %s [b'\\xc0\\xb5\\xd5\\x11\\xcf\\xf6\\xd7 \\xe9\\x89\"\\x9cu\\x94\\x11\\xc9YM\\xe3E\\xe2\\xff\\xe8\\x07\\xe3\\xb0\\xbf\\xc5\\xcc\\x83;\\xdc\\xd7e<x\\xdf\\xc8\\xcb\\xfb']\n",
                        "Bad pipe message: %s [b'<\\xc0\\x18\\x1e.\\x18X]\\xbb5\\x9a\\x9b\\xf50\\x17\\x81C\\x11 \\xcb\\xb9f[\\x0c\\x98\\xa4\\x94&kQBo\\x0c4P\\xdf\\xc2\\x82C\\x17\\x10\\xb2qb\\xc6G[\\xdd\\xfeX,\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\n",
                        "Bad pipe message: %s [b'']\n",
                        "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 \\x8f\\x1f\\xfa\\xe1\\xa5Q\\xb8\\xdcAs0\\x0fV\\x8a\\xe3\\xae6k\\xabu\\x89\\xba']\n",
                        "Bad pipe message: %s [b';\\n5\\xadj\\x85\\x85x\\xd8\\xa2\\xcc.]\\x02\\xb7\\xaa%g\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0', b\"\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\"]\n",
                        "Bad pipe message: %s [b'\\x03\\x08']\n",
                        "Bad pipe message: %s [b'\\x08\\x08\\t\\x08\\n\\x08']\n",
                        "Bad pipe message: %s [b'\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\n",
                        "Bad pipe message: %s [b'', b'\\x03\\x03']\n",
                        "Bad pipe message: %s [b'']\n",
                        "Bad pipe message: %s [b'R\\xday\\xd4}o\\xc2\\x96\\xf2\\x83m\\x8b\\xb5\\xaa?t\"\\xeb\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k']\n",
                        "Bad pipe message: %s [b'', b'\\x02']\n",
                        "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
                        "Bad pipe message: %s [b'\\xf65\\xce\\xfa\\xf4\\x8ek\\xfcj\\xd8\\x0f\\xa3\\xe2\\xa5\\x1c`W\\x82\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c']\n",
                        "Bad pipe message: %s [b'\\xe1!l%\\xe6w$3\\xa3B\\x84[\\xb6\\xa8\\x13hj\\xbc\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00']\n",
                        "Bad pipe message: %s [b'\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00']\n",
                        "Bad pipe message: %s [b'#\\x00\\x00\\x00\\x0f\\x00\\x01\\x01\\x15']\n",
                        "Bad pipe message: %s [b'\\xa1\\xd9\\xf9o\\xd2\\xd0ce\\x07\\x8d\\x87\\xf0\\xeb\\xbc\\x8a\\x94\\xdd\\xcf\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\x0f']\n",
                        "Bad pipe message: %s [b\"\\x93\\xca\\xb0'Tv\\xa5\\xe3\\x8c\\xac#\\xf8\\x91,\\x92\\xb6\\xe5\\x8a\\x00\"]\n",
                        "Bad pipe message: %s [b'\\x8d\\xe5E\\x9a\\x02\\x01K,de\\xff\\x14\\xb2\\xd6o\\xfe\\xf1W\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x00', b\"2\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\"]\n",
                        "Bad pipe message: %s [b'\\xf2\\x0c@\\xeb\\xf29\\xa1\\xa3\\\\G,\\xbe\\\\\\x1b\\x0f\\xbd\\x98\\x05\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00', b\"\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\"]\n",
                        "Bad pipe message: %s [b'\\x12\\xc0\\x08']\n"
                    ]
                }
            ],
            "source": [
                "preds"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 152,
            "id": "02545b0d",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['Hence the final answer in Korean is: 오타와']"
                        ]
                    },
                    "execution_count": 152,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "preds"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 153,
            "id": "75a88663",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "8"
                        ]
                    },
                    "execution_count": 153,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(pred.split())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 154,
            "id": "66d3dd29",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'오타와'"
                        ]
                    },
                    "execution_count": 154,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "pred = preds[-1].split(\":\")[-1].strip()\n",
                "pred"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 155,
            "id": "13e0413c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Prediction: 오타와\n",
                        "Label: 오타와\n",
                        "{'exact_match': 100.0, 'f1': 100.0}\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Prediction: {pred}\")\n",
                "print(f\"Label: {label}\")\n",
                "prediction = {\"prediction_text\": pred, \"id\": test_example[\"id\"]}\n",
                "reference = {}\n",
                "reference[\"answers\"] = test_example[\"answers\"]\n",
                "reference[\"id\"] = test_example[\"id\"]\n",
                "results = squad_metric.compute(\n",
                "            predictions=[prediction],\n",
                "            references=[reference]\n",
                "        )\n",
                "print(results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 165,
            "id": "bc555f12",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "em: 50.0 f1: 65.17197331387709: : 160it [1:59:08, 45.14s/it]               /home/t-kabirahuja/work/repos/MultilingualBlanketEval/mega/models/completion_models.py:98: UserWarning: Couldn't generate response, returning empty string as response\n",
                        "  warnings.warn(\n",
                        "em: 50.84033613445378 f1: 62.88800698400471: : 238it [2:57:23, 44.72s/it]  \n"
                    ]
                },
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: '/home/t-kabirahuja/.cache/huggingface/metrics/squad/default'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[165], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m reference[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m test_example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m reference[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m test_example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 44\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msquad_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreference\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m f1_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     48\u001b[0m em_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexact_match\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
                        "File \u001b[0;32m~/work/repos/MultilingualBlanketEval/envs/mega2env/lib/python3.8/site-packages/evaluate/module.py:432\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m compute_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize()\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/work/repos/MultilingualBlanketEval/envs/mega2env/lib/python3.8/site-packages/evaluate/module.py:481\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_feature_from_batch(batch)\n\u001b[0;32m--> 481\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n",
                        "File \u001b[0;32m~/work/repos/MultilingualBlanketEval/envs/mega2env/lib/python3.8/site-packages/evaluate/module.py:605\u001b[0m, in \u001b[0;36mEvaluationModule._init_writer\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# Get cache file name and lock it\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilelock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 605\u001b[0m     cache_file_name, filelock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_cache_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# get ready\u001b[39;00m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m cache_file_name\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilelock \u001b[38;5;241m=\u001b[39m filelock\n",
                        "File \u001b[0;32m~/work/repos/MultilingualBlanketEval/envs/mega2env/lib/python3.8/site-packages/evaluate/module.py:268\u001b[0m, in \u001b[0;36mEvaluationModule._create_cache_file\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    266\u001b[0m filelock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_concurrent_cache_files):\n\u001b[0;32m--> 268\u001b[0m     filelock \u001b[38;5;241m=\u001b[39m \u001b[43mFileLock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.lock\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m         filelock\u001b[38;5;241m.\u001b[39macquire(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
                        "File \u001b[0;32m~/work/repos/MultilingualBlanketEval/envs/mega2env/lib/python3.8/site-packages/datasets/utils/filelock.py:399\u001b[0m, in \u001b[0;36mUnixFileLock.__init__\u001b[0;34m(self, lock_file, timeout, max_filename_length)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lock_file, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, max_filename_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 399\u001b[0m     max_filename_length \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatvfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlock_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mf_namemax\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(lock_file, timeout\u001b[38;5;241m=\u001b[39mtimeout, max_filename_length\u001b[38;5;241m=\u001b[39mmax_filename_length)\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/t-kabirahuja/.cache/huggingface/metrics/squad/default'"
                    ]
                }
            ],
            "source": [
                "f1_sum = 0\n",
                "em_sum = 0\n",
                "avg_em = 0\n",
                "avg_f1 = 0\n",
                "\n",
                "run_details = {\"num_calls\": 0}\n",
                "\n",
                "pbar = tqdm(enumerate(test_dataset))\n",
                "\n",
                "for i, test_example in pbar:    \n",
                "    test_prompt = construct_translate_cot_prompt(test_example, tgt_lang, test=True)\n",
                "\n",
                "    prompt = [instruction_prompt] + few_shot_prompts + test_prompt\n",
                "    label = test_example[\"answers\"][\"text\"][0]\n",
                "    preds = []\n",
                "    for _ in range(20):\n",
                "        try:\n",
                "            pred = gpt3x_completion(\n",
                "                prompt,\n",
                "                model,\n",
                "                temperature=0,\n",
                "                evals_per_second=2,\n",
                "                run_details=run_details,\n",
                "                max_tokens=max_tokens\n",
                "            )\n",
                "            prompt += [{\"role\": \"assistant\", \"content\": pred}]\n",
                "            preds.append(pred)\n",
                "            if \"Hence the final answer\" in pred:\n",
                "                break\n",
                "        except:\n",
                "            pred = \"\" if preds == [] else pred\n",
                "            break\n",
                "            \n",
                "    if \"Hence the final answer\" in pred:\n",
                "        answer_pred = preds[-1].split(\":\")[-1].strip()\n",
                "    else:\n",
                "        answer_pred = \"\"\n",
                "    \n",
                "    \n",
                "    prediction = {\"prediction_text\": answer_pred, \"id\": test_example[\"id\"]}\n",
                "    reference = {}\n",
                "    reference[\"answers\"] = test_example[\"answers\"]\n",
                "    reference[\"id\"] = test_example[\"id\"]\n",
                "    results = squad_metric.compute(\n",
                "                predictions=[prediction],\n",
                "                references=[reference])\n",
                "    f1_sum += results[\"f1\"]\n",
                "    em_sum += results[\"exact_match\"]\n",
                "        \n",
                "    avg_f1 = f1_sum / (i+1)\n",
                "    avg_em = em_sum / (i+1)\n",
                "    \n",
                "#     wandb.log({\"f1\": avg_f1, \"em\": avg_em}, step = i+1)\n",
                "#     wandb.log(run_details, step = i+1)\n",
                "    pbar.set_description(f\"em: {avg_em} f1: {avg_f1}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b220e468",
            "metadata": {},
            "outputs": [],
            "source": [
                "run_details"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fedf012e",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}