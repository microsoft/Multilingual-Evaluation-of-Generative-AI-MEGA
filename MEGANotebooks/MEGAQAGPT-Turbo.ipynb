{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "8b0d19e8",
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "a19a5cff",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.chdir(\"../\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "026b1300",
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "from typing import List\n",
                "import spacy\n",
                "import openai\n",
                "import numpy as np\n",
                "import wandb\n",
                "from datasets import load_dataset\n",
                "from mega.data.load_datasets import load_xnli_dataset\n",
                "from mega.data.data_utils import choose_few_shot_examples\n",
                "from mega.prompting.instructions import INSTRUCTIONS\n",
                "from mega.prompting.prompting_utils import load_prompt_template\n",
                "from mega.utils.env_utils import load_openai_env_variables\n",
                "from mega.models.completion_models import get_model_pred, gpt3x_completion\n",
                "from mega.prompting.prompting_utils import construct_prompt, construct_qa_prompt\n",
                "from tqdm.notebook import tqdm\n",
                "from evaluate import load"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "73ef56fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make sure that {env_name}.env file is present in the envs/ directory\n",
                "env_name = \"vellm\"\n",
                "load_env(env_name=env_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "82cce2c0",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'2023-03-15-preview'"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# openai.api_version = \"2023-03-15-preview\"\n",
                "openai.api_version"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "2e764055",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'https://vellmapi.openai.azure.com/'"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "openai.api_base"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "1992175f",
            "metadata": {},
            "outputs": [],
            "source": [
                "model = \"gptturbo\"\n",
                "pivot_lang = \"en\"\n",
                "tgt_lang = \"ta\"\n",
                "prompt_name = \"answer_given_context_and_question\"\n",
                "few_shot_k = 0\n",
                "dataset = \"indicqa\"\n",
                "short_contexts = False\n",
                "max_tokens = 20"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "0fc5117e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
                        "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkabirahuja2431\u001b[0m (\u001b[33mscai-msri\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.15.0"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/home/t-kabirahuja/work/repos/MultilingualBlanketEval/wandb/run-20230421_190019-5prbdpgo</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Syncing run <strong><a href='https://wandb.ai/scai-msri/GPT-4-eval/runs/5prbdpgo' target=\"_blank\">brisk-sky-74</a></strong> to <a href='https://wandb.ai/scai-msri/GPT-4-eval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/scai-msri/GPT-4-eval' target=\"_blank\">https://wandb.ai/scai-msri/GPT-4-eval</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/scai-msri/GPT-4-eval/runs/5prbdpgo' target=\"_blank\">https://wandb.ai/scai-msri/GPT-4-eval/runs/5prbdpgo</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/scai-msri/GPT-4-eval/runs/5prbdpgo?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
                        ],
                        "text/plain": [
                            "<wandb.sdk.wandb_run.Run at 0x7fd655f99a60>"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "config = {\n",
                "    \"model\" : model,\n",
                "    \"pivot_lang\": pivot_lang,\n",
                "    \"tgt_lang\": tgt_lang,\n",
                "    \"prompt_name\": prompt_name,\n",
                "    \"few_shot_k\": few_shot_k,\n",
                "    \"dataset\": dataset,\n",
                "    \"short_contexts\": short_contexts,\n",
                "    \"max_tokens\": max_tokens\n",
                "}\n",
                "\n",
                "wandb.init(project=\"GPT-4-eval\", entity=\"scai-msri\", config=config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "645bc52f",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SpacySentenceTokenizer:\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.nlp = spacy.load('xx_ent_wiki_sm')\n",
                "        self.nlp.add_pipe(\"sentencizer\")\n",
                "        \n",
                "    def __call__(self, text: str) -> List[str]:\n",
                "        return list(map(lambda span: span.text, self.nlp(text).sents))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "57a7a04d",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_qa_dataset(dataset_name, lang, split, dataset_frac = 1, translate_test = False):\n",
                "    if dataset_name == \"indicqa\":\n",
                "        if split != \"train\":\n",
                "            dataset = load_dataset(\"ai4bharat/IndicQA\", f\"indicqa.{lang}\")[split]\n",
                "        else:\n",
                "            dataset = load_dataset(\"squad\")[split]\n",
                "    elif dataset_name == \"xquad\":\n",
                "        if split != \"train\":\n",
                "            dataset = load_dataset(\"xquad\", f\"xquad.{lang}\")[split]\n",
                "        else:\n",
                "            dataset = load_dataset(\"squad\")[split]\n",
                "    elif dataset_name == \"tydiqa\":\n",
                "        dataset = load_dataset(\"tydiqa\", 'secondary_task')[split]\n",
                "        dataset = dataset.map(lambda example: {\"lang\" : TYDIQA_LANG2CODES[example[\"id\"].split(\"-\")[0]]})\n",
                "        dataset = dataset.filter(lambda example: example[\"lang\"] == lang)\n",
                "    elif dataset_name == \"mlqa\":\n",
                "        if split == \"train\":\n",
                "            print(\"No Training Data for MLQA, switching to validation!\")\n",
                "            split = \"validation\"\n",
                "        if translate_test:\n",
                "            dataset_name = f\"mlqa-translate-test.{lang}\"\n",
                "        else:\n",
                "            dataset_name = f\"mlqa.{lang}.{lang}\"\n",
                "        \n",
                "        dataset = load_dataset(\"mlqa\", dataset_name)[split]\n",
                "    \n",
                "    else:\n",
                "        raise NotImplementedError()\n",
                "    N = len(dataset)\n",
                "    selector = np.arange(int(N * dataset_frac))\n",
                "    return dataset.select(selector)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "6a81d928",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Found cached dataset squad (/home/t-kabirahuja/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "892be46cce724223b9f91671bfb3a3b9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/2 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Found cached dataset indic_qa (/home/t-kabirahuja/.cache/huggingface/datasets/ai4bharat___indic_qa/indicqa.ta/1.0.0/f410c3a04e1e13303ea2e04267c0767261a938879f5ad7abf5ea57610444b55f)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "aa54a807fafc487085a5ee30789da57f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/1 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "train_dataset = load_qa_dataset(dataset,\n",
                "                                lang = pivot_lang,\n",
                "                                split=\"train\")\n",
                "test_dataset = load_qa_dataset(dataset,\n",
                "                                lang = tgt_lang,\n",
                "                                split=\"validation\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "5782b80f",
            "metadata": {},
            "outputs": [],
            "source": [
                "if short_contexts:\n",
                "    sent_tokenizer = SpacySentenceTokenizer() \n",
                "\n",
                "    train_dataset = train_dataset.map(lambda example: {\n",
                "        \"context\": [sent for sent in sent_tokenizer(example[\"context\"]) if example[\"answers\"][\"text\"][0] in sent][0]\n",
                "    }, num_proc = 8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "98827b9b",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_examples = choose_few_shot_examples(\n",
                "        train_dataset, few_shot_k, selection_criteria=\"random\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "b287a181",
            "metadata": {},
            "outputs": [],
            "source": [
                "PROMPTS_DICT = {\n",
                "    \"answer_given_context_and_question\" : \"\"\"{context}\n",
                "    Q: {question}\n",
                "\n",
                "    Referring to the passage above, the correct answer to the given question is:\n",
                "    {answer}\"\"\",\n",
                "    \n",
                "    \"lang_instruct_answer_given_context_and_question\" : \"\"\"{context}\n",
                "    Q: {question}\n",
                "\n",
                "    Referring to the passage above, the correct answer to the given question is? Please try to answer in {language} and ensure that the answer appears as it is in the passage.\n",
                "    A: {answer}\"\"\",\n",
                "    \n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "a45e8d1f",
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt_template = PROMPTS_DICT[prompt_name]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "1eb47ad6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "You are an NLP assistant whose purpose is to solve reading comprehension problems. You will be provided questions on a set of passages and you will need to provide the answer as it appears in the passage. The answer should be in the same language as the question and the passage.\n"
                    ]
                }
            ],
            "source": [
                "# Loading instruction for the task\n",
                "instruction = INSTRUCTIONS[\"xquad\"]\n",
                "print(instruction)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "b8367f96",
            "metadata": {},
            "outputs": [],
            "source": [
                "squad_metric = load(\"squad\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "7fd344b8",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[{'role': 'system',\n",
                            "  'content': 'You are an NLP assistant whose purpose is to solve reading comprehension problems. You will be provided questions on a set of passages and you will need to provide the answer as it appears in the passage. The answer should be in the same language as the question and the passage.'},\n",
                            " {'role': 'user',\n",
                            "  'content': '1962 ல் பத்மஸ்ரீ விருது வழங்கப்படுவதற்கு கால் நூற்றாண்டுக்கு முன்பே இந்திய அரசால் அன்னை தெரேசா அடையாளங்காணப்பட்டுள்ளார். 1972-ல், பன்னாட்டு புரிந்துணர்வுக்கான ஜவகர்லால் நேரு விருது, 1980-ல் இந்தியாவின் உயரிய குடிமக்கள் விருதான பாரத ரத்னா உட்பட இந்திய உயர்விருதுகளை அடுத்த பத்தாண்டுகளில் பெற்றார். அவரது அதிகாரபூர்வ வாழ்க்கைச்சரித்திரம், இந்திய ஆட்சிப் பணியாளரான நவீன் சாவ்லாவால் எழுதப்பட்டு 1992இல் வெளியிடப்பட்டது. அன்னை தெரசாவைப் பற்றிய எல்லா இந்தியாரும் உயர்வாகப் பார்க்கவில்லை. கல்கத்தாவில் பிறந்து லண்டனில் வாழ்ந்து கொண்டிருக்கும் அவரது விமர்சகரான அரூப் ச்சேட்டர்ஜி அவர் வாழ்ந்த காலத்தில் கல்கத்தாவின் முக்கிய அங்கமாக இருக்கவில்லையெனக் குறிப்பிட்டுள்ளார். அன்னை தெரேசா தனது சொந்த ஊரான கல்கத்தாவின் புகழைக் குலைத்து விட்டதாகக் அவர்  குறை கூறியுள்ளார். பாரதிய ஜனதா கட்சி கிறிஸ்துவ தலித்துக்கள் விஷயத்தில், அவரோடு மோதிய போதிலும், அவரது மரணத்தின் போது அவரைப் புகழ்ந்து, இறுதி சடங்கிற்குத் தனது பதிளாளை அனுப்பியது. ஆனால் விஸ்வ ஹிந்து பரிஷத்தோ, அரசு மரியாதையுடன் கூடிய இறுதிச்சடங்கினை செய்யும் அரசாங்கத்தின் முடிவுக்கு எதிர்ப்புத் தெரிவித்தது. அதன் நிர்வாகி கிரிராஜ் கிஷோர், \"அவரது முதல் கடமை கிறிஸ்துவத்திற்கே இருந்தது\" என்றுக் கூறினார். பொது நல சேவை தற்செயலானது. மேலும் அவர் கிறிஸ்துவர்களுக்கு சாதகமானவரென்றும், இறப்பின் வாயிலிலிருப்போருக்கு இரகசிய திருமுழுக்கை மேற்கொள்ளுபவரென்றும் குற்றஞ்சாட்டினார். ஆனால் ஃப்ரண்ட் லைன் பத்திரிகையளித்த முதல் பக்கமரியாதையில் இக்குற்றச்சாட்டுகளை அப்பட்டமான தவறாக நிராகரித்துள்ளது. அவரது சேவையைப் பற்றிய கல்கத்தாவாசிகளின் எண்ணத்தில், எந்தத் தாக்கத்தையும் இவை விளைவித்துவிடவில்லை என்றும் கூறியிருக்கிறது. இப்புகழ்மாலையை சூட்டிய ஆசிரியர் அவரது தன்னலமற்ற சேவை செய்யும் சக்தியையும், தைரியத்தையும் புகழ்ந்தபோதிலும், பொது கூட்டங்களில் அவர் கருக்கலைப்பை எதிர்ப்பதையும், அதை அரசியல் நோக்கமில்லாததாகக் காட்டிக்கொள்வதையும் குறை கூறியுள்ளார். அண்மையில், இந்திய நாளேடான தி டெலிக்ராப், அவர் வறியவர்களின் துன்பத்தைப் போக்க ஏதேனும் செய்தாரா அல்லது உணர்வுபூர்வமாக நெறிகளைத் தூண்டும் நோக்கத்தோடு, நோயாளிகளையும் இறப்போரையும் பராமரித்து வந்தாடு நின்று விட்டாரா என்பதைக் குறித்து விசாரிக்கும்படி உரோமைக்கு வேண்டுகோள் விடுக்கப்பட்டுள்ளது என்று கூறியுள்ளது. செப்டம்பர் 1997 ல் இறுதிச்சடங்கிற்கு முன்னதாக ஒரு வார காலம் அன்னை தெரேசாவின் உடல் கொல்கத்தாவின் புனித தோமையார் ஆலயத்தில் பொதுமக்கள் பார்வைக்கு வைக்கப்பட்டிருந்தது. அனைத்து மத ஏழைகளுக்கும் அவர் ஆற்றிய தொண்டுக்குப் பரிகாரமாக, இந்திய அரசின் அரசு மரியாதையுடன் கூடிய இறுதிச்சடங்கு செய்யப்பட்டது. தெற்காசிய மற்றும் கிழக்காசிய சேவைகளுக்காக 1962-ல், பன்னாட்டுப் புரிந்துணர்தலுக்கான பிலிப்பைன்ஸின் ரமன் மக்சேசே விருதைப் பெற்றார். அயல்நாடுகளில் தாழ்த்தப்பட்ட ஏழைகளின் மீதான கருணை நிறைந்த கவனத்தையும், அதற்காகவே அவர் வழிநடத்திச் செல்லும் புதிய சபையையும் இவ்விருதின் தீர்வுக்குழுமம் அங்கீகரிக்கிறது என்று விருதில் குறிப்பிடப்பட்டிருந்தது. 1970களின் தொடக்கத்திற்குள் அன்னை தெரேசா அனைத்துலகாலும் அறியப்பட்டார். 1969இன் ஆவணப்படமான மேல்கம் முக்கேரிட்ஜ்-ன், சம்திங்க் பியுடிபுல் பார் காட் -ம், அதே தலைப்புடைய அவரது புத்தகமும் அவரது புகழுக்கு வித்திட்டவைகளில் முக்கியமானவை ஆகும். முக்கேரிட்ஜ் அந்நேரத்தில் ஒரு ஆன்மீக பயணத்தில் ஆழ்ந்திருந்தார். அச்செய்திப்படத்தின் படப்பிடிப்பின் போது மோசமான ஒளியமைப்பு சூழலில், குறிப்பாக இறப்பின் வாயிலிலிருப்போருக்கான இல்லங்களில் எடுக்கப்பட்ட காட்சிகள் பயன்பாட்டுக்கு உகந்தவையாக இல்லையென அவர் முதலில் நினைத்தாலும், இந்தியாவிலிருந்து திரும்பிய பின்னர் அக்காட்சிதொகுப்பு மிக நல்ல ஒளியமைப்புடன் வந்திருந்தது. அன்னை தெரேசாவிடமிருந்தே வந்த தெய்வீக ஒளியர்ப்புதம் இது என முக்கேரிட்ஜ் பறைசாற்றினார். அப்படப்பிடிப்புக் குழுவின் மற்றவர்கள் அது புதுவித அதிநுண்ணிய வகை கோடாக் படச்சுருளால் ஏற்பட்ட விளைவு என்றெண்ணினர். முக்கேரிட்ஜ் பின்னர் கத்தோலிக்கராகச் சமயம் மாறினார். இவ்வேளையில் கத்தோலிக்கர் உலகம் முழுவதும் அன்னை தெரேசாவைப் வெளிப்படையாய் புகழ ஆரம்பித்தனர். 1971-ல் திருத்தந்தை ஆறாம் பவுல், அமைதிக்கான முதல் திருத்தந்தை இருபத்திமூன்றாம் யோவான் பரிசை, அவரின் ஏழை எளியோருக்கான சேவையையும் கிறிஸ்துவ நெறியின் பறைசாற்றலையும், அமைதிக்கான முயற்சியையும் பாராட்டி அவருக்கு அளித்தார். அதன் பிறகு பேசெம் இன் டெர்ரிஸ் விருதைப் பெற்றார். தான் மரித்தநாளிலிருந்து அன்னை தெரேசா புனிதத்துவத்தினை நோக்கி வேகமாக முன்னேறித் தற்பொழுது முக்தி பேறினை எட்டியிருக்கிறார். அன்னை தெரேசா அரசாங்கங்களாலும், மக்கள் அமைப்புகளாலும் பெருமைப்படுத்தப்பட்டிருக்கிறார். ஆஸ்திரேலிய சமுதாயத்திற்கு மட்டுமல்லாது ஒட்டுமொத்த மனித குலத்துக்கும் செய்த சேவைக்காக, 1982-ல் அவர் ஆர்டர் ஆஃப் ஆஸ்திரேலியாவின் கௌரவ தோழர் என்ற விருதைப் பெற்றார். இங்கிலாந்தும், அமெரிக்காவும் அடுத்தடுத்து விருதுகள் வழங்கின.\\n    Q: அன்னை தெரசாவுக்கு எப்போது பத்மஸ்ரீ விருது வழங்கப்பட்டது?\\n\\n    Referring to the passage above, the correct answer to the given question is:'}]"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "test_example = test_dataset[132]\n",
                "\n",
                "prompt, label = construct_qa_prompt(\n",
                "    train_examples,\n",
                "    test_example,\n",
                "    train_prompt_template=prompt_template,\n",
                "    test_prompt_template=prompt_template,\n",
                "    chat_prompt=True,\n",
                "    instruction=instruction\n",
                ")\n",
                "prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "02ecd577",
            "metadata": {},
            "outputs": [],
            "source": [
                "pred = gpt3x_completion(\n",
                "    prompt,\n",
                "    model,\n",
                "    temperature=0,\n",
                "    max_tokens=20\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "13e0413c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Prediction: 1962.\n",
                        "Label: 1962\n",
                        "{'exact_match': 100.0, 'f1': 100.0}\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Prediction: {pred}\")\n",
                "print(f\"Label: {label}\")\n",
                "prediction = {\"prediction_text\": pred, \"id\": test_example[\"id\"]}\n",
                "reference = {}\n",
                "reference[\"answers\"] = test_example[\"answers\"]\n",
                "reference[\"id\"] = test_example[\"id\"]\n",
                "results = squad_metric.compute(\n",
                "            predictions=[prediction],\n",
                "            references=[reference]\n",
                "        )\n",
                "print(results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "bc555f12",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "909cf71d1b9942588bb056284678da01",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "f1_sum = 0\n",
                "em_sum = 0\n",
                "avg_em = 0\n",
                "avg_f1 = 0\n",
                "\n",
                "run_details = {\"num_calls\": 0}\n",
                "\n",
                "pbar = tqdm(enumerate(test_dataset))\n",
                "\n",
                "for i, test_example in pbar:    \n",
                "    prompt, label = construct_qa_prompt(\n",
                "        train_examples,\n",
                "        test_example,\n",
                "        train_prompt_template=prompt_template,\n",
                "        test_prompt_template=prompt_template,\n",
                "        chat_prompt=True,\n",
                "        instruction=instruction\n",
                "    )\n",
                "    pred = gpt3x_completion(\n",
                "        prompt,\n",
                "        model,\n",
                "        temperature=0,\n",
                "        run_details=run_details,\n",
                "        max_tokens=max_tokens\n",
                "    )\n",
                "    prediction = {\"prediction_text\": pred, \"id\": test_example[\"id\"]}\n",
                "    reference = {}\n",
                "    reference[\"answers\"] = test_example[\"answers\"]\n",
                "    reference[\"id\"] = test_example[\"id\"]\n",
                "    results = squad_metric.compute(\n",
                "                predictions=[prediction],\n",
                "                references=[reference])\n",
                "    f1_sum += results[\"f1\"]\n",
                "    em_sum += results[\"exact_match\"]\n",
                "        \n",
                "    avg_f1 = f1_sum / (i+1)\n",
                "    avg_em = em_sum / (i+1)\n",
                "    \n",
                "    wandb.log({\"f1\": avg_f1, \"em\": avg_em}, step = i+1)\n",
                "    wandb.log(run_details, step = i+1)\n",
                "    pbar.set_description(f\"em: {avg_em} f1: {avg_f1}\")\n",
                "    time.sleep(1/2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b220e468",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}