{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160ff6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02807a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "import openai\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from mega.data.data_utils import choose_few_shot_examples\n",
    "from mega.prompting.instructions import INSTRUCTIONS\n",
    "from mega.prompting.prompting_utils import load_prompt_template\n",
    "from mega.utils.env_utils import load_env\n",
    "from mega.models.completion_models import get_model_pred, gpt3x_completion\n",
    "from mega.prompting.prompting_utils import construct_prompt, construct_cmxnli_prompt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdecbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that {env_name}.env file is present in the envs/ directory\n",
    "env_name = \"melange\"\n",
    "load_env(env_name=env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f254c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://gpttesting1.openai.azure.com/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5508b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-35-turbo-deployment\"\n",
    "prompt_name = \"GPT-3 style\"\n",
    "few_shot_k = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020573e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b925ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the extracted JSON file\n",
    "with open('gluecosdata/nli/all.json', 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    # Convert the JSON data to a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Read the text file with test set IDs\n",
    "    with open('gluecosdata/nli/test_ids.txt', 'r') as test_ids_file:\n",
    "        # Extract the IDs as a list of strings\n",
    "        test_ids = [int(line.strip()) for line in test_ids_file]\n",
    "        \n",
    "        # Split the DataFrame into train and test subsets based on the IDs\n",
    "        train_df = df[~df['ID'].isin(test_ids)].reset_index(drop=True)\n",
    "        test_df = df[df['ID'].isin(test_ids)].reset_index(drop=True)\n",
    "        \n",
    "        # Convert the train and test DataFrames to Dataset objects\n",
    "        train_dataset = Dataset.from_pandas(train_df)\n",
    "        test_dataset = Dataset.from_pandas(test_df)\n",
    "        \n",
    "        # Create a DatasetDict object with train and test datasets\n",
    "        dataset_dict = DatasetDict({'train': train_dataset, 'test': test_dataset})\n",
    "        \n",
    "    # Close the test IDs file\n",
    "    test_ids_file.close()\n",
    "\n",
    "# Close the JSON file\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a754c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 0,\n",
       " 'Premise ID': '465',\n",
       " 'Premise': 'FATHER\\nMain wapis hospital jaa raha hun .\\nRAHUL\\nMaa , main dieting pe hun , mere liye green tea please .\\nMOTHER\\nHaan , okay beta .\\nRAHUL\\nEk aur baat .. (he pulls something out of his pocket) Ye aapke liye ..\\nMOTHER\\nOh .. You are just .. Mera perfect baccha .\\n',\n",
       " 'Hypothesis': 'Dady wapas hospital ja rahe hain',\n",
       " 'Label': 'entailed'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a01cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FATHER\\nMain wapis hospital jaa raha hun .\\nRAHUL\\nMaa , main dieting pe hun , mere liye green tea please .\\nMOTHER\\nHaan , okay beta .\\nRAHUL\\nEk aur baat .. (he pulls something out of his pocket) Ye aapke liye ..\\nMOTHER\\nOh .. You are just .. Mera perfect baccha .\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"Premise\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954afeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{premise} Question: {hypothesis} True or False? ||| {label}\"\"\"\n",
    "verbalizer = { \"entailed\": \"True\", \"contradiction\": \"False\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "390d4bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an NLP assistant whose purpose is to solve Natural Language Inference (NLI) problems. NLI is the task of determining the inference relation between two (short, ordered) texts: entailment, contradiction, or neutral. Answer as concisely as possible in the same format as the examples below:\n"
     ]
    }
   ],
   "source": [
    "# Loading instruction for the task\n",
    "instruction = INSTRUCTIONS[\"xnli\"]\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a49b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting few-shot examples\n",
    "train_examples = choose_few_shot_examples(\n",
    "        train_dataset, few_shot_k, selection_criteria=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959a3916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an NLP assistant whose purpose is to solve Natural Language Inference (NLI) problems. NLI is the task of determining the inference relation between two (short, ordered) texts: entailment, contradiction, or neutral. Answer as concisely as possible in the same format as the examples below:'},\n",
       " {'role': 'user',\n",
       "  'content': \"ARIF\\nPhir se bol .. phir se bol .. Kitne ki ?\\nARIF\\nEk baar ... phir se bol .\\nSHAHID\\nHaah . 12 , 000\\nSHAHID\\nSir , meri naukri lag gayi .\\nWAR\\nKya baat hai . Mubarakaan .\\nSHAHID\\nLaw mein admission le raha hoon .\\nWAR\\nMashallah . Law kyon ?\\nSHAHID\\nTo Help people .\\nWAR\\nNahin Lawyer ka kaam hai client ko raasta dikhana , jahan woh apni madad khud kar sakein .\\nSHAHID\\nHaan .\\nWAR\\nHar imaandar lawyer apne imaandari mein ek jaisa hoga par har ek beimaan apni beimaani mein alag . Be a people's lawyer , Shahid . Tum mein kabiliyat hai .\\nSHAHID\\nShukriya , bhai jaan .\\nWAR\\nAchcha kaam hai yeh , Shahid agar tumhein parwaah hai galat aur sahi ki .\\nSHAHID\\nPeople's Lawyer .\\n Question: Lawyer ka kaam hai client ko raasta dikhana True or False? |||\"},\n",
       " {'role': 'assistant', 'content': 'True'},\n",
       " {'role': 'user',\n",
       "  'content': 'DHANIRAM\\nHmm .. Kya Ramashankarr hai ?\\nDHANIRAM\\nThee ..\\nAMRISH\\n14 .\\nDHANIRAM\\nNaam ?\\nAMRISH\\nShruti ..\\nDHANIRAM\\nNaukar ka ..\\nAMRISH\\nKhempal ..\\nDHANIRAM\\nTumhara ?\\nAMRISH\\nAmrish ..\\nDHANIRAM\\nRelative ?\\nAMRISH\\nMeri Bhateejee hai ..\\nDHANIRAM\\nHmmm ..\\n Question: Shruti AMRISH ki behen hai True or False? |||'},\n",
       " {'role': 'assistant', 'content': 'False'},\n",
       " {'role': 'user',\n",
       "  'content': \"MIKHAELO\\nThis ?\\nRANI\\nYes very good massage\\nMIKHAELO\\nIt's not for the neck\\nRANI\\npata hai ! Its for neck , back , shoulders aur haan head ! dadaji ke liye hai ... my grandfather\\nMIKHAELO\\nWhat ???\\nRANI\\nJodon mein dard hai na ... tch ... arthritis\\nRANI\\nfor mummy ... multicolour na ... (to herself) sab ke saath jayega\\nRANI\\nThis for chintu , my brother ... he loves playing chor police\\n Question: RANI ke dadaji ke joints mein pain hai True or False? |||\"},\n",
       " {'role': 'assistant', 'content': 'True'},\n",
       " {'role': 'user',\n",
       "  'content': 'FATHER\\nGarage mein hathoda pada hai . Ghar ki baaki cheezein bhi todh do ... TV , Fridge , AC ...\\nRAHUL\\nMeri galti thhi Dad . Mujhe gaadi chalana seekhna thha .\\nARJUN\\nBas ? Yeh toh daantne ke naam pe insult thha yaar . Tujhe naalayak , nikumma aur gadha bolna toh bhool hi gaye .\\nMOTHER\\nArjun ! Rahul ! Dadu bula rahe hain .\\n Question: ARJUN ne RAHUL ko naalayak , nikumma aur gadha bola. True or False? |||'},\n",
       " {'role': 'assistant', 'content': 'False'},\n",
       " {'role': 'user',\n",
       "  'content': 'DEBDAS\\nTum vivaah kar rahe ho , Pakhi se ...\\nVARUN\\nSagaai .\\nDEBDAS\\nKya baat hai Varun ? Kya chhupa rahe ho ?\\nVARUN\\nKuch nahin ...\\nDEBDAS\\nKuch to hai jo tum nahin kah rahe ho ...\\nDEBDAS\\nBajpai ji ko kya bataaoge ?\\nVARUN\\nPata nahin .\\nDEBDAS\\nTo phir sagaai kyon kar rahe ho ? Usse poora hi khatam karke jaane ka iraada hai ?\\nDEBDAS\\nSagaai kahaan hai ?\\nVARUN\\nMandir mein .\\nDEBDAS\\nKab ?\\nVARUN\\nKal ...\\n Question: DEBDAS kuchh chhupa raha hai True or False? |||'},\n",
       " {'role': 'assistant', 'content': 'False'},\n",
       " {'role': 'user',\n",
       "  'content': \"NEETU CHACHI\\nAnd look what I found in ..\\nMOTHER\\nArrey .. Haan .. Ye toh pata nahin kitni purani hain ... Yeh taste kar ---\\nNEETU CHACHI\\nIt's delicious ! Timmy ko bolo na mujhe kuch mutton recipes bheje , Sharic just loves this stuff .\\nMOTHER\\nHaan , ussey bolti hoon email karne ke liye .\\n Question: Mother Timmy ko mutton recipes email karne ke liye bolegi. True or False? |||\"},\n",
       " {'role': 'assistant', 'content': 'True'},\n",
       " {'role': 'user',\n",
       "  'content': 'SHAHID\\nHello .\\nRAVI PUJARI\\nTu sudhrega nahin na ?\\nSHAHID\\nKaun ?\\nRAVI PUJARI\\nTeri maa ka yaar , saale . Tere ko samjhaaonga nahin , ab udaaonga .\\nSHAHID\\nSun . Phone pe paise barbaad mat kar . Tu desh bhakt hai aur main gaddar , toh maar de mujhe . Main peeche nahin hatoonga .\\n Question: Ab RAVI PUJARI samjhaaega nahi, udaaega True or False? |||'},\n",
       " {'role': 'assistant', 'content': 'True'},\n",
       " {'role': 'user',\n",
       "  'content': \"GOVT. SECRETARY\\nAshwin ... kaise ho ?\\nASHWIN\\nGood Sir ...\\nGOVT. SECRETARY\\nAchha suno , jis meeting ke baare mein maine tumse baat kee thee na ...\\nASHWIN\\nJi ..\\nGOVT. SECRETARY\\nWoh kal 11 baje ke liye fix ho gayee hai ... Tumhare bahut saare chahne wale\\nASHWIN\\nI'll be there Sir ...\\nGOVT. SECREATRY\\nSee you . Bye .\\n Question: GOVT. SECRETARY ne ASHWIN ko achhe se sunne ko kaha.  True or False? |||\"},\n",
       " {'role': 'assistant', 'content': 'False'},\n",
       " {'role': 'user',\n",
       "  'content': 'SHYAMA\\nKaadha pee lo didi . Doctor sahab ne bola hai ...\\nSHYAMA\\nKaadha pee lo .\\nPAKHI\\nMain pee loongi , mez par rakh do .\\nSHYAMA\\nAbhi peeyo , hamaare saamne .\\nPAKHI\\nBola na mez par rakh do , pee loongi ...\\nPAKHI\\nMujhe maaf kar do .\\n Question: PAKHI ne SHYAMA se maafi maangi True or False? |||'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example = test_dataset[0]\n",
    "\n",
    "prompt, label = construct_cmxnli_prompt(\n",
    "    train_examples,\n",
    "    test_dataset[0],\n",
    "    train_prompt_template=template,\n",
    "    test_prompt_template=template,\n",
    "    chat_prompt=True,\n",
    "    instruction=instruction,\n",
    "    verbalizer=verbalizer\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b67c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: True\n",
      "Label: True\n",
      "Match: 1.0\n"
     ]
    }
   ],
   "source": [
    "prediction = gpt3x_completion(\n",
    "    prompt,\n",
    "    model,\n",
    "    temperature=0,\n",
    "    max_tokens=10\n",
    ")\n",
    "match = float(prediction.startswith(label))\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Match: {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7adde71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 448/448 [13:48<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7879464285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "preds = []\n",
    "labels = []\n",
    "for test_example in tqdm(test_dataset):\n",
    "    prompt, label = construct_cmxnli_prompt(\n",
    "        train_examples,\n",
    "        test_example,\n",
    "        train_prompt_template=template,\n",
    "        test_prompt_template=template,\n",
    "        chat_prompt=True,\n",
    "        instruction=instruction,\n",
    "        verbalizer=verbalizer\n",
    "    )\n",
    "    prediction = gpt3x_completion(\n",
    "        prompt,\n",
    "        model,\n",
    "        temperature=0,\n",
    "        max_tokens=10\n",
    "    )\n",
    "    time.sleep(1/2)\n",
    "    match = float(prediction.startswith(label))\n",
    "    preds.append(prediction)\n",
    "    labels.append(label)\n",
    "    matches.append(match)\n",
    "\n",
    "print(f\"Accuracy: {np.mean(matches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5887f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
