{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160ff6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02807a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "import openai\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from mega.data.data_utils import choose_few_shot_examples\n",
    "from mega.prompting.instructions import INSTRUCTIONS\n",
    "from mega.prompting.prompting_utils import load_prompt_template\n",
    "from mega.utils.env_utils import load_env\n",
    "from mega.models.completion_models import get_model_pred, gpt3x_completion\n",
    "from mega.prompting.prompting_utils import construct_prompt, construct_cmxnli_prompt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fdecbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that {env_name}.env file is present in the envs/ directory\n",
    "env_name = \"melange\"\n",
    "load_env(env_name=env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f254c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://gpttesting1.openai.azure.com/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5508b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-35-turbo-deployment\"\n",
    "prompt_name = \"GPT-3 style\"\n",
    "few_shot_k = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b925ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the extracted JSON file\n",
    "with open('gluecosdata/nli/all.json', 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    # Convert the JSON data to a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Read the text file with test set IDs\n",
    "    with open('gluecosdata/nli/test_ids.txt', 'r') as test_ids_file:\n",
    "        # Extract the IDs as a list of strings\n",
    "        test_ids = [int(line.strip()) for line in test_ids_file]\n",
    "        \n",
    "        # Split the DataFrame into train and test subsets based on the IDs\n",
    "        train_df = df[~df['ID'].isin(test_ids)].reset_index(drop=True)\n",
    "        test_df = df[df['ID'].isin(test_ids)].reset_index(drop=True)\n",
    "        \n",
    "        # Convert the train and test DataFrames to Dataset objects\n",
    "        train_dataset = Dataset.from_pandas(train_df)\n",
    "        test_dataset = Dataset.from_pandas(test_df)\n",
    "        \n",
    "        # Create a DatasetDict object with train and test datasets\n",
    "        dataset_dict = DatasetDict({'train': train_dataset, 'test': test_dataset})\n",
    "        \n",
    "    # Close the test IDs file\n",
    "    test_ids_file.close()\n",
    "\n",
    "# Close the JSON file\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a754c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 0,\n",
       " 'Premise ID': '465',\n",
       " 'Premise': 'FATHER\\nMain wapis hospital jaa raha hun .\\nRAHUL\\nMaa , main dieting pe hun , mere liye green tea please .\\nMOTHER\\nHaan , okay beta .\\nRAHUL\\nEk aur baat .. (he pulls something out of his pocket) Ye aapke liye ..\\nMOTHER\\nOh .. You are just .. Mera perfect baccha .\\n',\n",
       " 'Hypothesis': 'Dady wapas hospital ja rahe hain',\n",
       " 'Label': 'entailed'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a01cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FATHER\\nMain wapis hospital jaa raha hun .\\nRAHUL\\nMaa , main dieting pe hun , mere liye green tea please .\\nMOTHER\\nHaan , okay beta .\\nRAHUL\\nEk aur baat .. (he pulls something out of his pocket) Ye aapke liye ..\\nMOTHER\\nOh .. You are just .. Mera perfect baccha .\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"Premise\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954afeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{premise} Question: {hypothesis} True or False? ||| {label}\"\"\"\n",
    "verbalizer = { \"entailed\": \"True\", \"contradiction\": \"False\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "390d4bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an NLP assistant whose purpose is to solve Natural Language Inference (NLI) problems. NLI is the task of determining the inference relation between two (short, ordered) texts: entailment, contradiction, or neutral. Answer as concisely as possible in the same format as the examples below:\n"
     ]
    }
   ],
   "source": [
    "# Loading instruction for the task\n",
    "instruction = INSTRUCTIONS[\"xnli\"]\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a49b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting few-shot examples\n",
    "train_examples = choose_few_shot_examples(\n",
    "        train_dataset, few_shot_k, selection_criteria=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959a3916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SARA\\nMei n t oh rah oon gi na hin , l eki n tumhare liye ek aur nominee hota toh accha hota ..\\nDEEPAK\\nHaan achha hota ..\\nSARA\\nSoch lo phi r ... ready hoon main abhi bhi !\\nDEEPAK\\nSh ay a d p ro bl e m m ei n h ai n v o h ! Pa re s ha a n th e in us s d in su b ah subah !\\nSARA\\nKaun ?\\nDEEPAK\\nVoh B 48 . 1 st floor . B ataya tha na ...\\nSARA\\nVoh teenon bachiyan ...\\n Question: usne B 48 1st floor bataya tha True or False? |||\\nTrue\\nDR. SWAMY\\nYou know the law Ashwin .. Investigative officers narco test mein maujud nahin reh sakte ..\\nASHWIN\\nSwamy Saab .. Main pahadi ki nok pe khada hoon .. Ek kood mili .. Aur khai paar .. Please ..\\nDR. SWAMY\\nAshwin bachhe ki tarah zid mat karo .. I can't help in this , please ..\\nASHWIN\\nAchha phone do apna .\\nDR. SWAMY\\nKisey phone laga rahe ho ?\\nASHWIN\\nKhud ko ? (He gives her the phone back\\nLo baat karo .\\nASHWIN\\nHello Dr . Swamy ? Kaisi hain ?\\nDR. SWAMY\\nAshwin kya hai ye ?\\nASHWIN\\nLive telecast . Ye to law mein mana nahi hai na ? Aur test ke dauraan koi sawaal soojha to main Dr Mohanty ko text karoonga . Jaaiye ander . Der ho rahee hai .\\n Question: DR. SWAMY bachhe ki tarah zid kar raha hai True or False? |||\\nFalse\\nMRS.KAPOOR\\n--Poora laal ho gaya hai par Thank God , koi nishaan nahin aaya , plastic surgery karani padti toh ?\\nMRS.KAPOOR\\nOkay .. Bye .\\nMR.KAPOOR\\nChartered flight nahin hai , chali jayegi .\\nMRS.KAPOOR\\nPunctuality ke liye nobel prize hota , to tumhare dad ko do teen to mil he jaate .\\nMR.KAPOOR\\nRahul , serious hone ka time aa gaya hai , Ab kaam par concentrate karna shuru karo . Tum jo bhi chahte the , woh sab kuch tumhein diya gaya hai . And I'm still waiting for that GOLD !! (gives him a cold pat on the shoulder) Have a good Christmas .\\nMRS.KAPOOR\\nOh , main to bhool he gayi baby , Merry Christmas .\\nMRS.KAPOOR\\nGet a hair cut .\\n Question:  Dad ko nobel prize milne wala hai.  True or False? |||\\nFalse\\nZOYA\\nLekin maine clearly room 906 maanga tha ...\\nRECEPTIONIST\\nI admit maam ki galti ho sakti hai but 904 bilkul same room hai ...\\nZOYA\\nNahi but 5 mera number hai ... mujhe suit karta hai ... numerology mein ...\\nRECEPTIONIST\\n906 jaise hi khali hota hai hum aapko shift ...\\nZOYA\\nAap guest se request karkey rooms exchange nahi kar saktey ? Agar same rooms hain toh ...\\nRECEPTIONIST\\nMaam 906 mein hamarey ek regular guest hain ... Saalon se usi room mein rehtey hain ... Long life Sir ... Aap hi ki baat kar raha tha ...\\nSHAHARYAR BHATTI\\nHello Ji ... Shaharyar Bhatti from Pindi ...\\n Question: ZOYA ne room 906 maanga tha.  True or False? |||\\nTrue\\nDEEPAK\\nIt could have all gone wrong .\\nFALAK\\nMere baad wapis Andrea ko bulatey - pata nahi kya kya kehtey - tang aa gayi thi !\\nDEEPAK\\nStick to coffee . Chai bahut kharab banati ho tum !\\nFALAK\\nI know - aap pehle aadmi hain jisne yeh sach bola !\\nDEEPAK\\nAajkal mere jaise hi sach boltey hain !\\n Question: FALAK chai bahut kharaab banaati hai True or False? |||\\nTrue\\nSOHAIL\\nBhai case wapas lena hi hoga ?\\nSHAHID\\nPar kyon ?\\nSOHAIL\\nJo ho gaya usko badal sakte kya . Phir ?\\nSHAHID\\nSohail , phir yahi hota rahega .\\nSOHAIL\\nAbu chahta hai .\\nSHAHID\\nAbu ? Shahid stands ..\\nSOHAIL\\nBhai mat jao . Woh maar dalega sab ko .. Sohail starts crying .\\nSHAHID\\nTheek hai . Shahid comes out of jail . He opens his car door and wham ... he bangs it back in anger .\\n Question: SOHAIL ki baat sun kar SHAHID dar gaya. True or False? |||\\nFalse\\nKASTURI\\nNa h i s a m a j h m e in a a r a h a h a i puttar .\\nSANJEEV\\nKya baat hai Andrea ?\\nANDREA\\nNothing Sir voh ...\\nSANJEEV\\nArrey ... have ... chill yaar .. kaam kiya hai itna ... le na abhi !\\nSANJEEV\\nKya hai ... hua kya hai ... life mein sab hota hai yaar ... chal na beer pi !\\nSANJEEV\\nArrey your beer ... leke ja naa tu !\\n Question:  SANJEEV ANDREA ko beer na pine ko keh raha hai.  True or False? |||\\nFalse\\nCHACHA\\nAchchi jagah hai , tumhare liye perfect hoga Rahul ...\\nRAHUL\\nOk Tia .. tumhare uncle se baat kar lo ... paperwork shuru karte hain ...\\nCHACHA\\nTum se milkar achcha laga .\\nRAHUL\\nTu nahin aa raha ?\\nARJUN\\nMain .. aata hoon ...\\nTIA\\nOh Thanks , thanks !\\n Question: CHACHA ko jagah achhi lag rahi hai True or False? |||\\nTrue\\nSHYAMA\\nKaadha pee lo didi . Doctor sahab ne bola hai ...\\nSHYAMA\\nKaadha pee lo .\\nPAKHI\\nMain pee loongi , mez par rakh do .\\nSHYAMA\\nAbhi peeyo , hamaare saamne .\\nPAKHI\\nBola na mez par rakh do , pee loongi ...\\nPAKHI\\nMujhe maaf kar do .\\n Question: PAKHI ne SHYAMA se maafi maangi True or False? |||\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example = test_dataset[0]\n",
    "\n",
    "prompt, label = construct_cmxnli_prompt(\n",
    "    train_examples,\n",
    "    test_dataset[0],\n",
    "    train_prompt_template=template,\n",
    "    test_prompt_template=template,\n",
    "    chat_prompt=False,\n",
    "    instruction=instruction,\n",
    "    verbalizer=verbalizer\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b67c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: False\n",
      "Label: True\n",
      "Match: 0.0\n"
     ]
    }
   ],
   "source": [
    "prediction = gpt3x_completion(\n",
    "    prompt,\n",
    "    model,\n",
    "    temperature=0,\n",
    "    max_tokens=10\n",
    ")\n",
    "match = float(prediction.startswith(label))\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Match: {match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7adde71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 448/448 [11:58<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7209821428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "preds = []\n",
    "labels = []\n",
    "for test_example in tqdm(test_dataset):\n",
    "    prompt, label = construct_cmxnli_prompt(\n",
    "        train_examples,\n",
    "        test_example,\n",
    "        train_prompt_template=template,\n",
    "        test_prompt_template=template,\n",
    "        chat_prompt=False,\n",
    "        instruction=instruction,\n",
    "        verbalizer=verbalizer\n",
    "    )\n",
    "    prediction = gpt3x_completion(\n",
    "        prompt,\n",
    "        model,\n",
    "        temperature=0,\n",
    "        max_tokens=10\n",
    "    )\n",
    "    time.sleep(1/2)\n",
    "    match = float(prediction.startswith(label))\n",
    "    preds.append(prediction)\n",
    "    labels.append(label)\n",
    "    matches.append(match)\n",
    "\n",
    "print(f\"Accuracy: {np.mean(matches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0335e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
