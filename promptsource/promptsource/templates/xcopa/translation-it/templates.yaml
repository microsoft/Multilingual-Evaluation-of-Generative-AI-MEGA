dataset: xcopa/translation-it
templates:
  07dc5774-1e57-4c9a-8696-02f589051b53: !Template
    answer_choices: choice1 ||| choice2
    id: 07dc5774-1e57-4c9a-8696-02f589051b53
    jinja: "{{ premise }} \n\nWhat's the best option?\n- choice1 : {{choice1}}\n-\
      \ choice2 : {{choice2}}\n\nWe are looking for {% if question == \"cause\" %}\
      \ a cause {% else %} an effect {% endif %}\n||| {% if label != -1 %}{{answer_choices[label]}}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: best_option discrete
    reference: Discrete version of the best_option prompt
  744047dc-1298-45a2-8d68-d67e3f834ded: !Template
    answer_choices: '{{choice1 }} ||| {{choice2}}'
    id: 744047dc-1298-45a2-8d68-d67e3f834ded
    jinja: '"{{ answer_choices[0] }}" or "{{ answer_choices[1] }}"? {{ premise }}
      {% if question == "cause" %} because {% else %} so {% endif %} ||| {% if label
      != -1 %}{{ answer_choices[label] }}{% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: "C1 or C2? premise, so/because\u2026"
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  f67eb599-4667-4d2e-88cf-d792cc08a1b6: !Template
    answer_choices: choice1 ||| choice2
    id: f67eb599-4667-4d2e-88cf-d792cc08a1b6
    jinja: "{{ premise }} {% if question == \"cause\" %} This happened because...\
      \ {% else %} As a consequence... {% endif %}\nHelp me pick the more plausible\
      \ option:\n- choice1: {{choice1}}\n- choice2: {{choice2}} \nAnswer: ||| {% if\
      \ label != -1 %}{{ answer_choices[label] }}{%endif%}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: plausible_alternatives_discrete
    reference: Discrete version of plausible_alternatives prompt
