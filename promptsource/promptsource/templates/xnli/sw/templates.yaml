dataset: xnli
subset: sw
templates:
  0326c085-1097-4736-9e12-c87e5974fc43: !Template
    answer_choices: True ||| Neither ||| False
    id: 0326c085-1097-4736-9e12-c87e5974fc43
    jinja: "'{{premise}}\n      Question: {{hypothesis}} True, False, or Neither?\
      \ ||| {{ answer_choices[label]\n      }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: GPT-3 style
    reference: '''Same as reported in Figure G7 of the GPT-3 paper, except that there       is
      no task identifying tokens like "anli R1: ".'''
  04b1c6cd-3091-461c-a968-a5c4ebb3ef6e: !Template
    answer_choices: Yes ||| Maybe ||| No
    id: 04b1c6cd-3091-461c-a968-a5c4ebb3ef6e
    jinja: '''{{premise}} Are we justified in saying that "{{hypothesis}}"? Yes, no,
      or maybe? ||| {{ answer_choices[label] }} '''
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - en
      metrics:
      - Accuracy
      original_task: false
    name: justified in saying
    reference: Webson & Pavlick 2021
  0df07101-bafe-41db-ba54-386d5b12cba4: !Template
    answer_choices: Always ||| Sometimes ||| Never
    id: 0df07101-bafe-41db-ba54-386d5b12cba4
    jinja: Suppose it's true that {{premise}} Then, is {{hypothesis}} {{always}},
      {{sometimes}}, or {{never}} true? ||| {{ answer_choices[label]}}
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: always/sometimes/never
    reference: Sanh et al. 2021
  113227f0-92bd-48f6-8ba8-a68b03f46287: !Template
    answer_choices: Kweli ||| Wala ||| Uongo
    id: 113227f0-92bd-48f6-8ba8-a68b03f46287
    jinja: '{{premise}}

      Swali: {{hypothesis}} kweli, uongo, au wala? ||| {{ answer_choices[label] }}'
    metadata: &id001 !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: Bing-Translated GPT-3 style
    reference: 'Translated to sw version  of: Same as reported in Figure G7 of the
      GPT-3 paper, except that there is no task identifying tokens like "anli R1:
      ".'
  31dc1f14-8c14-4ad8-9525-a0c61ea00b00: !Template
    answer_choices: True ||| Inconclusive ||| False
    id: 31dc1f14-8c14-4ad8-9525-a0c61ea00b00
    jinja: '''Take the following as truth: {{premise}} Then the following statement:
      "{{hypothesis}}" is {{"true"}}, {{"false"}}, or  {{"inconclusive"}}? ||| {{
      answer_choices[label] }}'''
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: take the following as truth
    reference: Sanh et al. 2021
  344250c2-56c9-4a4c-8bdf-cc882bcce852: !Template
    answer_choices: Correct ||| Inconclusive ||| Incorrect
    id: 344250c2-56c9-4a4c-8bdf-cc882bcce852
    jinja: '{{premise}} Using only the above description and what you know about the
      world, {{hypothesis}} is definitely correct, incorrect, or inconclusive? |||
      {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: MNLI crowdsource
    reference: Adapted from Williams et al. 2018's instructions to crowdsourcing workers.
  37d2f061-06b0-4aa3-af53-871a2b06748f: !Template
    answer_choices: True ||| Neither ||| False
    id: 37d2f061-06b0-4aa3-af53-871a2b06748f
    jinja: '{{premise}}

      Question: {{hypothesis}} True, False, or Neither? ||| {{ answer_choices[label]
      }}'
    metadata: *id001
    name: GPT-3 style
    reference: 'Same as reported in Figure G7 of the GPT-3 paper, except that there
      is no task identifying tokens like "anli R1: ".'
  55740462-6ea6-48c4-b05c-b6eeddb1c5c9: !Template
    answer_choices: Yes ||| Maybe ||| No
    id: 55740462-6ea6-48c4-b05c-b6eeddb1c5c9
    jinja: Suppose {{premise}} Can we infer that {{hypothesis}}? Yes, no, or maybe?
      ||| {{ answer_choices[label] }}
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: can we infer
    reference: Webson & Pavlick 2021
  6c67e364-554d-486e-994e-1e3d1430b5ad: !Template
    answer_choices: Yes ||| Maybe ||| No
    id: 6c67e364-554d-486e-994e-1e3d1430b5ad
    jinja: '{{premise}} Based on the previous passage, is it true that "{{hypothesis}}"?
      Yes, no, or maybe? ||| {{ answer_choices[label] }}'
    metadata: &id002 !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: based on the previous passage
    reference: '"Adapted from the BoolQ prompts in Schick & Sch\xFCtze 2021."'
  7c946a42-9070-422e-98d1-828cd330811a: !Template
    answer_choices: True ||| Inconclusive ||| False
    id: 7c946a42-9070-422e-98d1-828cd330811a
    jinja: '''{{premise}} Based on that information, is the claim: {{hypothesis}}
      {{true}}, {{false}}, or {{inconclusive}}? ||| {{ answer_choices[label] }}'''
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: claim true/false/inconclusive
    reference: Sanh et al. 2021
  8bd0976c-7b11-4585-b790-890bd00d13f6: !Template
    answer_choices: Yes ||| Maybe ||| No
    id: 8bd0976c-7b11-4585-b790-890bd00d13f6
    jinja: '{{premise}} Question: Does this imply that {{hypothesis}}? Yes, no, or
      maybe? ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: does this imply
    reference: Sanh et al. 2021
  a3bccb37-1a9e-4810-a7c1-d0b88581b90d: !Template
    answer_choices: Yes ||| Maybe ||| No
    id: a3bccb37-1a9e-4810-a7c1-d0b88581b90d
    jinja: Given that {{premise}} Does it follow that {{hypothesis}} Yes, no, or maybe?
      ||| {{ answer_choices[label] }}
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: does it follow that
    reference: Sanh et al. 2021
  a54e86c3-3590-48ac-ba06-0fe78ab13fcf: !Template
    answer_choices: Guaranteed ||| Possible ||| Impossible
    id: a54e86c3-3590-48ac-ba06-0fe78ab13fcf
    jinja: Assume it is true that {{premise}} Therefore, {{hypothesis}} is {{guaranteed}},
      {{possible}}, or {{impossible}}? ||| {{ answer_choices[label] }}
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: guaranteed/possible/impossible
    reference: Sanh et al. 2021
  aa56d20e-9a68-44f9-a865-6ddf5192b9e5: !Template
    answer_choices: Ndiyo ||| Labda ||| Hapana
    id: aa56d20e-9a68-44f9-a865-6ddf5192b9e5
    jinja: '{{premise}} Kulingana na kifungu kilichopita, ni kweli kwamba "{{hypothesis}}"?
      Ndiyo, hapana, au labda? ||| {{ answer_choices[label] }}'
    metadata: *id002
    name: Bing-Translated based on the previous passage
    reference: "Translated to sw version  of: Adapted from the BoolQ prompts in Schick\
      \ & Sch\xFCtze 2021."
  c0b922ef-07e4-41eb-9aa2-85b75eaae719: !Template
    answer_choices: Yes ||| Maybe ||| No
    id: c0b922ef-07e4-41eb-9aa2-85b75eaae719
    jinja: '''Given {{premise}} Is it guaranteed true that "{{hypothesis}}"? Yes,
      no, or maybe? ||| {{ answer_choices[label] }} '''
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: guaranteed true
    reference: Webson & Pavlick 2021
  c6e7741a-ea2c-46c8-b477-f209702420d2: !Template
    answer_choices: Yes ||| Maybe ||| No
    id: c6e7741a-ea2c-46c8-b477-f209702420d2
    jinja: '''Given {{premise}} Should we assume that "{{hypothesis}}" is true? Yes,
      no, or maybe? ||| {{ answer_choices[label] }} '''
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: should assume
    reference: Webson & Pavlick 2021
  cd8c4848-0bd5-4e63-91da-d1d211c722b0: !Template
    answer_choices: Yes ||| Maybe ||| No
    id: cd8c4848-0bd5-4e63-91da-d1d211c722b0
<<<<<<< HEAD
    jinja: "'Given that {{premise}} Therefore, it must be true that \"{{hypothesis}}\"\
      ?\n      Yes, no, or maybe? ||| {{ answer_choices[label] }} '"
=======
    jinja: '''Given that {{premise}} Therefore, it must be true that {{hypothesis}}?
      Yes, no, or maybe? ||| {{ answer_choices[label] }} '''
>>>>>>> b7a6466... Bloom debugging and sw templates fix
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: must be true
    reference: Sanh et al. 2021
  dcf42259-f2dd-42e1-947a-251da29dddfe: !Template
    answer_choices: Always ||| Sometimes ||| Never
    id: dcf42259-f2dd-42e1-947a-251da29dddfe
    jinja: 'Keeping in mind the above text, consider: {{hypothesis}} Is this {{"always"}},
      {{"sometimes"}}, or {{"never"}} correct? ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: consider always/sometimes/never
    reference: Sanh et al. 2021
