{
    "prompt": [
        {
            "role": "user",
            "content": "Please fill the dataset card for the XQuAD dataset. You can use the following schema:\nlanguages: \n- \"List of ISO 639-1 code for languages covered in the dataset\"\n- lang1\n- lang2\n...\n- langM\npretty_name: \"Pretty Name of the Dataset\"\ntags:\n- tag1\n- tag2\ndataset_info:\n    features:\n        - name: \"name of the feature1\"\n          dtype: \"dtype of the feature1\"\n        ...\n        - name: \"name of the featureN\"\n          dtype: \"dtype of the featureN\"\n    splits:\n        train:\n            num_examples: \"number of examples in the train split\"\n        validation:\n            num_examples: \"number of examples in the validation split\"\n        test:\n            num_examples: \"number of examples in the test split\"\ndataset_summary: \"Summary of the dataset's description\"\n and the following example:\nlanguage:\n  - ar\n  - bg\n  - de\n  - el\n  - en\n  - es\n  - fr\n  - hi\n  - ru\n  - sw\n  - th\n  - tr\n  - ur\n  - vi\n  - zh\npaperswithcode_id: xnli\npretty_name: Cross-lingual Natural Language Inference\ndataset_info:\n  features:\n    - name: premise\n      dtype: string\n    - name: hypothesis\n      dtype: string\n    - name: label\n      dtype:\n        class_label:\n          names:\n            \"0\": entailment\n            \"1\": neutral\n            \"2\": contradiction\n  splits:\n    train:\n      num_examples: 392702\n    validation:\n      num_examples: 2490\n    test:\n      num_examples: 5010\ndataset_summary: XNLI is a subset of a few thousand examples from MNLI which has been translated\ninto a 14 different languages (some low-ish resource). As with MNLI, the goal is\nto predict textual entailment (does sentence A imply/contradict/neither sentence\nB) and is a classification task (given two sentences, predict one of three\nlabels).\n"
        }
    ],
    "response": "languages:\n- \"List of ISO 639-1 code for languages covered in the dataset\"\n- en\n- es\n- de\npretty_name: \"Cross-lingual Question Answering Dataset (XQuAD)\"\ntags:\n- question answering\n- cross-lingual\ndataset_info:\n    features:\n        - name: \"id\"\n          dtype: \"string\"\n        - name: \"context\"\n          dtype: \"string\"\n        - name: \"question\"\n          dtype: \"string\"\n        - name: \"answers\"\n          dtype: \"List of dictionaries\"\n          value: \"{'text': 'answer text', 'answer_start': 'start position of answer in context'}\"\n        - name: \"title\"\n          dtype: \"string\"\n        - name: \"url\"\n          dtype: \"string\"\n    splits:\n        train:\n            num_examples: 240\n        validation:\n            num_examples: 60\n        test:\n            num_examples: 57\ndataset_summary: XQuAD is a cross-lingual question answering dataset, which consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set of SQuAD v1.1, translated by professional translators into ten languages: Spanish (es), German (de), Greek (el), Russian (ru), Turkish (tr), Arabic (ar), Vietnamese (vi), Thai (th), Chinese (zh), and Hindi (hi). The dataset is designed to evaluate cross-lingual question answering performance."
}