{
    "prompt": [
        {
            "role": "user",
            "content": "Please fill the dataset card for the XQuAD dataset. You can use the following schema:\nlanguages: \n- \"List of ISO 639-1 code for languages covered in the dataset\"\n- lang1\n- lang2\n...\n- langM\npretty_name: \"Pretty Name of the Dataset\"\ntags:\n- tag1\n- tag2\ndataset_info:\n    features:\n        - name: \"name of the feature1\"\n          dtype: \"dtype of the feature1\"\n        ...\n        - name: \"name of the featureN\"\n          dtype: \"dtype of the featureN\"\n    splits:\n        train:\n            num_examples: \"number of examples in the train split\"\n        validation:\n            num_examples: \"number of examples in the validation split\"\n        test:\n            num_examples: \"number of examples in the test split\"\ndataset_summary: \"Summary of the dataset's description\"\n and the following example:\nlanguage:\n  - ar\n  - bg\n  - de\n  - el\n  - en\n  - es\n  - fr\n  - hi\n  - ru\n  - sw\n  - th\n  - tr\n  - ur\n  - vi\n  - zh\npaperswithcode_id: xnli\npretty_name: Cross-lingual Natural Language Inference\ndataset_info:\n  features:\n    - name: premise\n      dtype: string\n    - name: hypothesis\n      dtype: string\n    - name: label\n      dtype:\n        class_label:\n          names:\n            \"0\": entailment\n            \"1\": neutral\n            \"2\": contradiction\n  splits:\n    train:\n      num_examples: 392702\n    validation:\n      num_examples: 2490\n    test:\n      num_examples: 5010\ndataset_summary: XNLI is a subset of a few thousand examples from MNLI which has been translated\ninto a 14 different languages (some low-ish resource). As with MNLI, the goal is\nto predict textual entailment (does sentence A imply/contradict/neither sentence\nB) and is a classification task (given two sentences, predict one of three\nlabels).\n"
        }
    ],
    "response": "languages:\n  - ar\n  - de\n  - el\n  - en\n  - es\n  - hi\n  - ru\n  - th\n  - tr\n  - vi\n  - zh\npretty_name: XQuAD\ntags:\n  - question_answering\n  - multilingual\ndataset_info:\n  features:\n    - name: context\n      dtype: string\n    - name: question\n      dtype: string\n    - name: id\n      dtype: string\n    - name: answers\n      dtype:\n        list:\n          item_type:\n            dict:\n              keys:\n                - name: text\n                  dtype: string\n                - name: answer_start\n                  dtype: int\n  splits:\n    train:\n      num_examples: 0\n    validation:\n      num_examples: 11900\n    test:\n      num_examples: 0\ndataset_summary: XQuAD (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating the performance of multilingual question-answering models. It consists of a subset of 240 paragraphs and 1190 question-answer pairs from the English SQuAD v1.1 dataset, which have been professionally translated into 10 languages: Arabic, German, Greek, Spanish, Hindi, Russian, Thai, Turkish, Vietnamese, and Chinese. The goal is to predict the correct answer to a given question based on the provided context paragraph."
}