{
    "prompt": [
        {
            "role": "user",
            "content": "Please fill the dataset card for the XCOPA dataset. You can use the following schema:\nlanguages: \n- \"List of ISO 639-1 code for languages covered in the dataset\"\n- lang1\n- lang2\n...\n- langM\npretty_name: \"Pretty Name of the Dataset\"\ntags:\n- tag1\n- tag2\ndataset_info:\n    features:\n        - name: \"name of the feature1\"\n          dtype: \"dtype of the feature1\"\n        ...\n        - name: \"name of the featureN\"\n          dtype: \"dtype of the featureN\"\n    splits:\n        train:\n            num_examples: \"number of examples in the train split\"\n        validation:\n            num_examples: \"number of examples in the validation split\"\n        test:\n            num_examples: \"number of examples in the test split\"\ndataset_summary: \"Summary of the dataset's description\"\n and the following example:\nlanguage:\n  - ar\n  - bg\n  - de\n  - el\n  - en\n  - es\n  - fr\n  - hi\n  - ru\n  - sw\n  - th\n  - tr\n  - ur\n  - vi\n  - zh\npaperswithcode_id: xnli\npretty_name: Cross-lingual Natural Language Inference\ndataset_info:\n  features:\n    - name: premise\n      dtype: string\n    - name: hypothesis\n      dtype: string\n    - name: label\n      dtype:\n        class_label:\n          names:\n            \"0\": entailment\n            \"1\": neutral\n            \"2\": contradiction\n  splits:\n    train:\n      num_examples: 392702\n    validation:\n      num_examples: 2490\n    test:\n      num_examples: 5010\ndataset_summary: XNLI is a subset of a few thousand examples from MNLI which has been translated\ninto a 14 different languages (some low-ish resource). As with MNLI, the goal is\nto predict textual entailment (does sentence A imply/contradict/neither sentence\nB) and is a classification task (given two sentences, predict one of three\nlabels).\n"
        }
    ],
    "response": "languages:\n  - ar\n  - bg\n  - de\n  - el\n  - en\n  - es\n  - fr\n  - hi\n  - ru\n  - sw\n  - th\n  - tr\n  - ur\n  - vi\n  - zh\npaperswithcode_id: xcopa\npretty_name: Cross-lingual Choice of Plausible Alternatives\ntags:\n  - natural language processing\n  - question answering\n  - multilingual\ndataset_info:\n  features:\n    - name: question\n      dtype: string\n    - name: choices\n      dtype: list\n    - name: answer\n      dtype: int\n  splits:\n    train:\n      num_examples: 14130\n    validation:\n      num_examples: 1960\n    test:\n      num_examples: 1960\ndataset_summary: XCOPA is a multilingual dataset that consists of 14 languages and is designed to evaluate the ability of models to perform commonsense causal reasoning. The dataset is derived from the English COPA dataset and is translated into multiple languages. The task is to choose the most plausible alternative given a premise and two possible alternatives."
}