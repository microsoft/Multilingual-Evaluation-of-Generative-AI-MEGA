{
    "prompt": [
        {
            "role": "user",
            "content": "Please fill the dataset card for the MLQA dataset. You can use the following schema:\nlanguages: \n- \"List of ISO 639-1 code for languages covered in the dataset\"\n- lang1\n- lang2\n...\n- langM\npretty_name: \"Pretty Name of the Dataset\"\ntags:\n- tag1\n- tag2\ndataset_info:\n    features:\n        - name: \"name of the feature1\"\n          dtype: \"dtype of the feature1\"\n        ...\n        - name: \"name of the featureN\"\n          dtype: \"dtype of the featureN\"\n    splits:\n        train:\n            num_examples: \"number of examples in the train split\"\n        validation:\n            num_examples: \"number of examples in the validation split\"\n        test:\n            num_examples: \"number of examples in the test split\"\ndataset_summary: \"Summary of the dataset's description\"\n"
        }
    ],
    "response": "languages: \n- ar\n- de\n- en\n- es\n- hi\n- vi\n- zh\npretty_name: \"MLQA: Multilingual Question Answering\"\ntags:\n- question_answering\n- multilingual\ndataset_info:\n    features:\n        - name: \"title\"\n          dtype: \"string\"\n        - name: \"context\"\n          dtype: \"string\"\n        - name: \"question\"\n          dtype: \"string\"\n        - name: \"id\"\n          dtype: \"string\"\n        - name: \"answers\"\n          dtype: \"list of dictionaries\"\n    splits:\n        train:\n            num_examples: \"N/A\"\n        validation:\n            num_examples: \"7,200\"\n        test:\n            num_examples: \"7,200\"\ndataset_summary: \"MLQA (MultiLingual Question Answering) is a dataset for evaluating cross-lingual question answering performance. The dataset contains over 5K extractive QA instances (12K in English) in SQuAD format in seven languages - English, Arabic, German, Spanish, Hindi, Vietnamese, and Simplified Chinese. MLQA is highly parallel, with QA instances parallel between 4 different languages on average.\""
}