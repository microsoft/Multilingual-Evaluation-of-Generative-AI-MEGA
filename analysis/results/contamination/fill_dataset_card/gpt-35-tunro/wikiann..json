{
    "prompt": [
        {
            "role": "user",
            "content": "Please fill the dataset card for the WikiANN dataset. You can use the following schema:\nlanguages: \n- \"List of ISO 639-1 code for languages covered in the dataset\"\n- lang1\n- lang2\n...\n- langM\npretty_name: \"Pretty Name of the Dataset\"\ntags:\n- tag1\n- tag2\ndataset_info:\n    features:\n        - name: \"name of the feature1\"\n          dtype: \"dtype of the feature1\"\n        ...\n        - name: \"name of the featureN\"\n          dtype: \"dtype of the featureN\"\n    splits:\n        train:\n            num_examples: \"number of examples in the train split\"\n        validation:\n            num_examples: \"number of examples in the validation split\"\n        test:\n            num_examples: \"number of examples in the test split\"\ndataset_summary: \"Summary of the dataset's description\"\n"
        }
    ],
    "response": "languages:\n- \"en\"\n- \"de\"\n- \"es\"\n- \"fr\"\n- \"it\"\n- \"nl\"\n- \"pl\"\n- \"pt\"\n- \"ru\"\n- \"sv\"\npretty_name: \"WikiANN\"\ntags:\n- \"text classification\"\n- \"named entity recognition\"\n- \"multilingual\"\ndataset_info:\n    features:\n        - name: \"text\"\n          dtype: \"string\"\n        - name: \"label\"\n          dtype: \"string\"\n    splits:\n        train:\n            num_examples: 587,794\n        validation:\n            num_examples: 73,474\n        test:\n            num_examples: 73,474\ndataset_summary: \"WikiANN is a multilingual dataset for named entity recognition and text classification. It consists of Wikipedia articles in 10 different languages, annotated with named entities and classified into 4 categories: person, location, organization, and miscellaneous. The dataset is useful for training and evaluating models for multilingual NER and text classification tasks.\""
}